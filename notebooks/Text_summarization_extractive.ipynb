{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization  \n",
    "Text summarization is the process of distilling the most important information from a source (or sources) to produce an abridged version or summary.  \n",
    "<img src=\"img/text_sum.png\" alt=\"Markdown Monster icon\" style=\"float: center; margin-right: 10px;\" />  \n",
    "\n",
    "The objective of this project is to build a model that can create relevant summaries for reviews written on Wine reviews. This dataset contains above 130k reviews, and is hosted on [Kaggle](https://www.kaggle.com/zynicide/wine-reviews)  \n",
    "\n",
    "\n",
    "### Types of Text Summarization Methods  \n",
    "Text summarization methods can be classified into different types  \n",
    "<img src=\"img/text_sum_types.png\" alt=\"Markdown Monster icon\" style=\"float: center; margin-right: 10px;\" />  \n",
    "\n",
    "i. Based on input type:  \n",
    "\n",
    "    Single Document, where the input length is short. Many of the early summarization systems dealt with single document summarization.\n",
    "    Multi Document, where the input can be arbitrarily long.  \n",
    "\n",
    "ii. Based on the purpose:  \n",
    "\n",
    "    Generic, where the model makes no assumptions about the domain or content of the text to be summarized and treats all inputs as homogeneous. The majority of the work that has been done revolves around generic summarization.  \n",
    "    Domain-specific, where the model uses domain-specific knowledge to form a more accurate summary. For example, summarizing research papers of a specific domain, biomedical documents, etc.  \n",
    "    Query-based, where the summary only contains information which answers natural language questions about the input text.  \n",
    "\n",
    "iii. Based on output type:  \n",
    "\n",
    "    Extractive, where important sentences are selected from the input text to form a summary. Most summarization approaches today are extractive in nature.  \n",
    "    Abstractive, where the model forms its own phrases and sentences to offer a more coherent summary, like what a human would generate. This approach is definitely a more appealing, but much more difficult than extractive summarization.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from time import time\n",
    "import heapq\n",
    "\n",
    "# from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "%matplotlib inline\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deep, dense and pure from the opening bell, th...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Slightly gritty black-fruit aromas include a s...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lush cedary black-fruit aromas are luxe and of...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This re-named vineyard was formerly bottled as...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The producer sources from two blocks of the vi...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elegance, complexity and structure come togeth...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From 18-year-old vines, this supple well-balan...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A standout even in this terrific lineup of 201...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This wine is in peak condition. The tannins an...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>With its sophisticated mix of mineral, acid an...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  points\n",
       "0   This tremendous 100% varietal wine hails from ...      96\n",
       "1   Ripe aromas of fig, blackberry and cassis are ...      96\n",
       "2   Mac Watson honors the memory of a wine once ma...      96\n",
       "3   This spent 20 months in 30% new French oak, an...      96\n",
       "4   This is the top wine from La Bégude, named aft...      95\n",
       "5   Deep, dense and pure from the opening bell, th...      95\n",
       "6   Slightly gritty black-fruit aromas include a s...      95\n",
       "7   Lush cedary black-fruit aromas are luxe and of...      95\n",
       "8   This re-named vineyard was formerly bottled as...      95\n",
       "9   The producer sources from two blocks of the vi...      95\n",
       "10  Elegance, complexity and structure come togeth...      95\n",
       "11  From 18-year-old vines, this supple well-balan...      95\n",
       "12  A standout even in this terrific lineup of 201...      95\n",
       "13  This wine is in peak condition. The tannins an...      95\n",
       "14  With its sophisticated mix of mineral, acid an...      95"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "\n",
    "path = '/Users/ndah/NEC/aims_nlp/wine_review/'\n",
    "data = pd.read_csv(path + \"winemag-data_first150k.csv\", nrows=5000, usecols =['points', 'description'], encoding='utf-8')\n",
    "data = data.dropna()\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# in this step we are going to remove code syntax from text \n",
    "def normalize_text(text):\n",
    "    \n",
    "    tm1 = re.sub('<pre>.*?</pre>', '', text, flags=re.DOTALL)\n",
    "    tm2 = re.sub('<code>.*?</code>', '', tm1, flags=re.DOTALL)\n",
    "    tm3 = re.sub('<[^>]+>©', '', tm1, flags=re.DOTALL)\n",
    "    \n",
    "    return tm3.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description_cleaned_1'] = data['description'].map(lambda x: normalize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalizing text-----\n",
      "\n",
      "This spent 20 months in 30% new French oak, and incorporates fruit from Ponzi's Aurora, Abetina and Madrona vineyards, among others. Aromatic, dense and toasty, it deftly blends aromas and flavors of toast, cigar box, blackberry, black cherry, coffee and graphite. Tannins are polished to a fine sheen, and frame a finish loaded with dark chocolate and espresso. Drink now through 2032.\n",
      "\n",
      "After normalizing text-----\n",
      "\n",
      "This spent 20 months in 30% new French oak, and incorporates fruit from Ponzi's Aurora, Abetina and Madrona vineyards, among others. Aromatic, dense and toasty, it deftly blends aromas and flavors of toast, cigar box, blackberry, black cherry, coffee and graphite. Tannins are polished to a fine sheen, and frame a finish loaded with dark chocolate and espresso. Drink now through 2032.\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "print('Before normalizing text-----\\n')\n",
    "print(data['description'][n])\n",
    "print('\\nAfter normalizing text-----\\n')\n",
    "print(data['description_cleaned_1'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\n",
    "punctuations = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~©'\n",
    "\n",
    "def cleanup_text(docs, logging=False):\n",
    "    \n",
    "    texts = []\n",
    "    doc = nlp(docs, disable=['parser', 'ner'])\n",
    "    tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "    tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "    tokens = ' '.join(tokens)\n",
    "    texts.append(tokens)\n",
    "    return pd.Series(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description_cleaned'] = data['description_cleaned_1'].apply(lambda x: cleanup_text(x, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews description with punctuatin and stopwords---\n",
      "\n",
      "This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022â2030.\n",
      "\n",
      "Reviews description after removing punctuation and stopwrods---\n",
      "\n",
      "tremendous 100 varietal wine hail oakville age three year oak . juicy red cherry fruit compelling hint caramel greet palate frame elegant fine tannin subtle minty tone background . balanced rewarding start finish year ahead develop nuance . enjoy 2022â2030 .\n"
     ]
    }
   ],
   "source": [
    "print('Reviews description with punctuatin and stopwords---\\n')\n",
    "print(data['description_cleaned_1'][0])\n",
    "print('\\nReviews description after removing punctuation and stopwrods---\\n')\n",
    "print(data['description_cleaned'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(1, 2, 1)\n",
    "# (data['points']).plot.hist(bins=30, figsize=(10,4), edgecolor='white',range=[0,150])\n",
    "# plt.xlabel('Number of points', fontsize=17)\n",
    "# plt.ylabel('frequency', fontsize=17)\n",
    "# plt.tick_params(labelsize=15)\n",
    "# plt.title('Number of points description', fontsize=17)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze reviews description lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_lens = data['description_cleaned'].map(lambda x: len(x.split()))\n",
    "n, bins, patches = plt.hist(review_lens, 50, density=True, facecolor='g', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizer using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert Paragraphs to Sentences: We first need to convert the whole paragraph into sentences. The most common way of converting paragraphs to sentences is to split the paragraph whenever a period is encountered.\n",
    "\n",
    "2. Text Preprocessing: After converting paragraph to sentences, we need to remove all the special characters, stop words and numbers from all the sentences.\n",
    "\n",
    "3. Tokenizing the Sentences: We need to tokenize all the sentences to get all the words that exist in the sentences\n",
    "\n",
    "4. Find Weighted Frequency of Occurrence: Next we need to find the weighted frequency of occurrences of all the words. We can find the weighted frequency of each word by dividing its frequency by the frequency of the most occurring word.\n",
    "\n",
    "5. Replace Words by Weighted Frequency in Original Sentences: The final step is to plug the weighted frequency in place of the corresponding words in original sentences and finding their sum. It is important to mention that weighted frequency for the words removed during preprocessing (stop words, punctuation, digits etc.) will be zero and therefore is not required to be added\n",
    "\n",
    "6. Sort Sentences in Descending Order of Sum: The final step is to sort the sentences in inverse order of their sum. The sentences with highest frequencies summarize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text_without_removing_dot, cleaned_text):\n",
    "    \n",
    "    sample_text = text_without_removing_dot\n",
    "    doc = nlp(sample_text)\n",
    "    sentence_list=[]\n",
    "    for idx, sentence in enumerate(doc.sents): # we are using spacy for sentence tokenization\n",
    "        sentence_list.append(re.sub(r'[^\\w\\s]','',str(sentence)))\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    word_frequencies = {}  \n",
    "    for word in nltk.word_tokenize(cleaned_text):  \n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "\n",
    "\n",
    "    summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    print(\"Original Text:\\n\")\n",
    "    print(text_without_removing_dot)\n",
    "    print('\\n\\nSummarized text:\\n')\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "This re-named vineyard was formerly bottled as deLancellotti. You'll find striking minerality underscoring chunky black fruits. Accents of citrus and graphite comingle, with exceptional midpalate concentration. This is a wine to cellar, though it is already quite enjoyable. Drink now through 2030.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "Accents of citrus and graphite comingle with exceptional midpalate concentration This is a wine to cellar though it is already quite enjoyable Youll find striking minerality underscoring chunky black fruits This renamed vineyard was formerly bottled as deLancellotti Drink now through 2030\n"
     ]
    }
   ],
   "source": [
    "generate_summary(data['description_cleaned_1'][8], data['description_cleaned'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "Elegance, complexity and structure come together in this drop-dead gorgeous winethat ranks among Italy's greatest whites. It opens with sublime yellow spring flower, aromatic herb and orchard fruit scents. The creamy, delicious palate seamlessly combines juicy white peach, ripe pear and citrus flavors while white almond and savory mineral notes grace the lingering finish.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "The creamy delicious palate seamlessly combines juicy white peach ripe pear and citrus flavors while white almond and savory mineral notes grace the lingering finish Elegance complexity and structure come together in this dropdead gorgeous winethat ranks among Italys greatest whites It opens with sublime yellow spring flower aromatic herb and orchard fruit scents\n"
     ]
    }
   ],
   "source": [
    "generate_summary(data['description_cleaned_1'][10], data['description_cleaned'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "import gc\n",
    "import string\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "from helper.contractions import CONTRACTION_MAP\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>US</td>\n",
       "      <td>This re-named vineyard was formerly bottled as...</td>\n",
       "      <td>Silice</td>\n",
       "      <td>95</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Chehalem Mountains</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>BergstrÃ¶m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>US</td>\n",
       "      <td>The producer sources from two blocks of the vi...</td>\n",
       "      <td>Gap's Crown Vineyard</td>\n",
       "      <td>95</td>\n",
       "      <td>60.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Sonoma Coast</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Blue Farm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "8           8      US  This re-named vineyard was formerly bottled as...   \n",
       "9           9      US  The producer sources from two blocks of the vi...   \n",
       "\n",
       "                     designation  points  price    province  \\\n",
       "0              Martha's Vineyard      96  235.0  California   \n",
       "2  Special Selected Late Harvest      96   90.0  California   \n",
       "3                        Reserve      96   65.0      Oregon   \n",
       "8                         Silice      95   65.0      Oregon   \n",
       "9           Gap's Crown Vineyard      95   60.0  California   \n",
       "\n",
       "             region_1           region_2             variety      winery  \n",
       "0         Napa Valley               Napa  Cabernet Sauvignon       Heitz  \n",
       "2      Knights Valley             Sonoma     Sauvignon Blanc    Macauley  \n",
       "3   Willamette Valley  Willamette Valley          Pinot Noir       Ponzi  \n",
       "8  Chehalem Mountains  Willamette Valley          Pinot Noir  BergstrÃ¶m  \n",
       "9        Sonoma Coast             Sonoma          Pinot Noir   Blue Farm  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/ndah/NEC/aims_nlp/wine_review/'\n",
    "data = pd.read_csv(path + \"winemag-data_first150k.csv\", nrows=8000, encoding='latin1')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence tokenization\n",
    "We can use the NLTK’s sentence tokenizer to obtain the sentence level tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenizer(text):\n",
    "    \"\"\"Modulke to create sentenc tokens\"\"\"\n",
    "    return sent_tokenize(text, language = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = data['description'].map(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mac Watson honors the memory of a wine once made by his mother in this tremendously delicious, balanced and complex botrytised white.',\n",
       " 'Dark gold in color, it layers toasted hazelnut, pear compote and orange peel flavors, reveling in the succulence of its 122 g/L of residual sugar.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip-Thought Encoder\n",
    "\n",
    "We need a way to generate fixed length vector representations for each sentence in our reviews. These representations should encode the inherent semantics and the meaning of the corresponding sentence. The well known Skip-Gram Word2Vec method for generating word embeddings can give us word embeddings for individual words that are present in our model’s vocabulary (some [fancier approaches](https://arxiv.org/abs/1607.04606) can also generate embeddings for words which are not in the model vocabulary using subword information).  \n",
    "\n",
    "For sentence embeddings, one easy way is to take a weighted sum of the word vectors for the words contained in the sentence. We take a weighted sum because frequently occurring words such as ‘and’, ‘to’ and ‘the’, provide little or no information about the sentence. Some rarely occurring words, which are unique to a few sentences have much more representative power. Hence, we take the weights as being inversely related to the frequency of word occurrence. This method is described in detail in this [paper](https://openreview.net/pdf?id=SyK00v5xx).\n",
    "\n",
    "However, these unsupervised methods do not take the sequence of words in the sentence into account. This may incur undesirable losses in model performance. To overcome this, I chose to instead train a Skip-Thought sentence encoder in a supervised manner using Wikipedia dumps as training data. The Skip-Thoughts model consists of two parts:\n",
    "\n",
    "1. Encoder Network: The encoder is typically a GRU-RNN which generates a fixed length vector representation h(i) for each sentence S(i) in the input. The encoded representation h(i) is obtained by passing final hidden state of the GRU cell (i.e. after it has seen the entire sentence) to multiple dense layers.  \n",
    "\n",
    "2. Decoder Network: The decoder network takes this vector representation h(i) as input and tries to generate two sentences — S(i-1) and S(i+1), which could occur before and after the input sentence respectively. Separate decoders are implemented for generation of previous and next sentences, both being GRU-RNNs. The vector representation h(i) acts as the initial hidden state for the GRUs of the decoder networks.\n",
    "\n",
    "\n",
    "Given a dataset containing a sequence of sentences, the decoder is expected to generate the previous and next sentences, word by word. The encoder-decoder network is trained to minimize the sentence reconstruction loss, and in doing so, the encoder learns to generate vector representations which encode enough information for the decoder, so that it can generate neighboring sentences. These learned representations are such that embeddings of semantically similar sentences are closer to each other in vector space, and therefore are suitable for clustering. The sentences in our emails are given as input to the encoder network to obtain the desired vector representations. This Skip-Thoughts approach for obtaining sentence embeddings is described in detail in this [paper](https://arxiv.org/abs/1506.06726).  \n",
    "\n",
    "Skipthought code can be found [here](https://github.com/ryankiros/skip-thoughts) \n",
    "\n",
    "\n",
    "#### Clustering  \n",
    "After generating sentence embeddings for each sentence in an review, the approach is to cluster these embeddings in high-dimensional vector space into a pre-defined number of clusters. The number of clusters will be equal to desired number of sentences in the summary. I chose the numbers of sentences in the summary to be equal to the square root of the total number of sentence in the review. One can also have it as being equal to, say, _30%_ of the total number of sentences.  \n",
    "\n",
    "#### Summarization  \n",
    "Each cluster of sentence embeddings can be interpreted as a set of semantically similar sentences whose meaning can be expressed by just one candidate sentence in the summary. The candidate sentence is chosen to be the sentence whose vector representation is closest to the cluster center. Candidate sentences corresponding to each cluster are then ordered to form a summary for a review. The order of the candidate sentences in the summary is determined by the positions of the sentences in their corresponding clusters in the original review. For example, a candidate sentence is chosen as the first line in the summary if most of the sentences that lie in its cluster occur at the beginning of the review.  \n",
    "\n",
    "*As this method essentially extracts some candidate sentences from the text to form a summary, it is known as Extractive Sumarization*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "EMBEDDING_FILE = '/Users/ndah/NEC/aims_nlp/glove.6B/glove.6B.100d.txt'\n",
    "glove_embeddings = open(EMBEDDING_FILE, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_dict = dict()\n",
    "\n",
    "for embeddings in glove_embeddings:\n",
    "    embedding_tokens = embeddings.split()\n",
    "    emb_word = embedding_tokens[0]\n",
    "    emb_vector = np.asarray(embedding_tokens[1:], dtype='float32')\n",
    "    embedd_dict[emb_word] = emb_vector\n",
    "\n",
    "glove_embeddings.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    words = text.strip().split()\n",
    "    words_expand = []\n",
    "    for word in words:\n",
    "        if word in CONTRACTION_MAP.keys():\n",
    "            words_expand.append(CONTRACTION_MAP[word])\n",
    "        else:\n",
    "            words_expand.append(word)\n",
    "            \n",
    "    text_expand = ' '.join(words_expand)\n",
    "    return text_expand\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    \n",
    "    return stripped_text\n",
    "\n",
    "\n",
    "def cleanup_text(text):\n",
    "    text = expand_contractions(text)\n",
    "    text = strip_html_tags(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def sentence_embedding(tokens, word2vec):\n",
    "    \"\"\"\n",
    "    Naive embeddings: Calculates the embedding for entire sentence by taking the average of all words\n",
    "    \"\"\"\n",
    "    tokens_emb =[]\n",
    "    for token in tokens:\n",
    "        embedding_vector = word2vec.get(token)\n",
    "        if embedding_vector is not None:\n",
    "            tokens_emb.append(embedding_vector)\n",
    "\n",
    "    return np.mean(np.array(tokens_emb), axis=0)\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def spacy_lemmatizer(sentence):\n",
    "    spacy_sentence = nlp(sentence)\n",
    "    tokens = []\n",
    "    for word in spacy_sentence:\n",
    "        if not word.is_stop:\n",
    "            tokens.append(word.lemma_)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def embedding(sentence_tokens, word2vec):\n",
    "    \"\"\"Calculates the embedding of each sentence in the review\"\"\"\n",
    "    sentence_enc = []\n",
    "    for sentence in sentence_tokens:\n",
    "        sentence_clean = cleanup_text(sentence)\n",
    "        tokens = spacy_lemmatizer(sentence_clean)\n",
    "        res = list(sentence_embedding(tokens, word2vec))\n",
    "        \n",
    "        sentence_enc.append(res)\n",
    "        \n",
    "    return np.array(sentence_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(reviews, word2vec):\n",
    "    \"\"\"\n",
    "    Performs summarization of reviews\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        \n",
    "        sent_tokens = sent_tokenize(review.strip())\n",
    "        \n",
    "        review_enc = embedding(sent_tokens, word2vec)        \n",
    "        n_clusters = int(np.ceil(len(review_enc)**0.5))\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        kmeans = kmeans.fit(review_enc)\n",
    "        \n",
    "        avg = []\n",
    "        closest = []\n",
    "        for j in range(n_clusters):\n",
    "            idx = np.where(kmeans.labels_ == j)[0]\n",
    "            avg.append(np.mean(idx))\n",
    "            \n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, review_enc)\n",
    "        ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "        review_summary = ' '.join([sent_tokens[closest[idx]] for idx in ordering])\n",
    "        \n",
    "        summary.append(review_summary)\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>2987</td>\n",
       "      <td>US</td>\n",
       "      <td>The color of oxblood, this meaty, tannic wine ...</td>\n",
       "      <td>Estate</td>\n",
       "      <td>89</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rogue Valley</td>\n",
       "      <td>Southern Oregon</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Folin Cellars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>4643</td>\n",
       "      <td>US</td>\n",
       "      <td>Bold, penetrating tannins and bright cranberry...</td>\n",
       "      <td>Moffett Block</td>\n",
       "      <td>88</td>\n",
       "      <td>32.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>Finger Lakes</td>\n",
       "      <td>Finger Lakes</td>\n",
       "      <td>BlaufrÃ¤nkisch</td>\n",
       "      <td>Atwater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>US</td>\n",
       "      <td>There's a cantaloupe-like ripeness on the nose...</td>\n",
       "      <td>XCV</td>\n",
       "      <td>91</td>\n",
       "      <td>38.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Paso Robles Willow Creek District</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>RhÃ´ne-style White Blend</td>\n",
       "      <td>Jada Vineyard &amp; Winery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>US</td>\n",
       "      <td>Silky in cherry and strawberry with a dense mi...</td>\n",
       "      <td>Spire</td>\n",
       "      <td>88</td>\n",
       "      <td>48.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Carneros-Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Cuvaison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>5471</td>\n",
       "      <td>US</td>\n",
       "      <td>From a particular block with limestone soils, ...</td>\n",
       "      <td>Coteau Blanc</td>\n",
       "      <td>88</td>\n",
       "      <td>45.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Carneros</td>\n",
       "      <td>Napa-Sonoma</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Chardenet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 country                                        description  \\\n",
       "2987        2987      US  The color of oxblood, this meaty, tannic wine ...   \n",
       "4643        4643      US  Bold, penetrating tannins and bright cranberry...   \n",
       "336          336      US  There's a cantaloupe-like ripeness on the nose...   \n",
       "687          687      US  Silky in cherry and strawberry with a dense mi...   \n",
       "5471        5471      US  From a particular block with limestone soils, ...   \n",
       "\n",
       "        designation  points  price    province  \\\n",
       "2987         Estate      89   32.0      Oregon   \n",
       "4643  Moffett Block      88   32.0    New York   \n",
       "336             XCV      91   38.0  California   \n",
       "687           Spire      88   48.0  California   \n",
       "5471   Coteau Blanc      88   45.0  California   \n",
       "\n",
       "                               region_1         region_2  \\\n",
       "2987                       Rogue Valley  Southern Oregon   \n",
       "4643                       Finger Lakes     Finger Lakes   \n",
       "336   Paso Robles Willow Creek District    Central Coast   \n",
       "687                Carneros-Napa Valley             Napa   \n",
       "5471                           Carneros      Napa-Sonoma   \n",
       "\n",
       "                       variety                  winery  \n",
       "2987                     Syrah           Folin Cellars  \n",
       "4643            BlaufrÃ¤nkisch                 Atwater  \n",
       "336   RhÃ´ne-style White Blend  Jada Vineyard & Winery  \n",
       "687                 Pinot Noir                Cuvaison  \n",
       "5471                Chardonnay               Chardenet  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(n = 5)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = test['description'].to_list()\n",
    "test_summary = summarize(test['description'].to_list(), embedd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "The color of oxblood, this meaty, tannic wine pours espresso, black licorice and composted earth around tart blackberry fruit. It's aromatic, spicy and nicely balanced.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "The color of oxblood, this meaty, tannic wine pours espresso, black licorice and composted earth around tart blackberry fruit. It's aromatic, spicy and nicely balanced.\n",
      "\n",
      "Original Text:\n",
      "\n",
      "Bold, penetrating tannins and bright cranberry acidity lend a tight frame to this classically styled BlaufrÃ¤nkisch, a.k.a. Lemberger. Crisp-tart blackberry and blueberry flavors are accented by bramble and herb notes that linger long on the finish. Its quite closed now, but should show well after 2018.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "Bold, penetrating tannins and bright cranberry acidity lend a tight frame to this classically styled BlaufrÃ¤nkisch, a.k.a. Its quite closed now, but should show well after 2018.\n",
      "\n",
      "Original Text:\n",
      "\n",
      "There's a cantaloupe-like ripeness on the nose of this blend of 37% Grenache Blanc, 33% Viognier and 30% Roussanne, but not overdone, layered with seared white peach, caramelized pear, poached apple and almond aromas. The palate is more restrained and quite grippy, with flavors of green-apple skins, Bosc pear and a touch of honey.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "There's a cantaloupe-like ripeness on the nose of this blend of 37% Grenache Blanc, 33% Viognier and 30% Roussanne, but not overdone, layered with seared white peach, caramelized pear, poached apple and almond aromas. The palate is more restrained and quite grippy, with flavors of green-apple skins, Bosc pear and a touch of honey.\n",
      "\n",
      "Original Text:\n",
      "\n",
      "Silky in cherry and strawberry with a dense midpalate of refined oak, this delicately hued Pinot comes from a single, hillside block of Cuvaison's Carneros property. With pretty aromas of violet and rose, it has richness that isn't overdone, a nice expression of the appellation's power and finesse.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "Silky in cherry and strawberry with a dense midpalate of refined oak, this delicately hued Pinot comes from a single, hillside block of Cuvaison's Carneros property. With pretty aromas of violet and rose, it has richness that isn't overdone, a nice expression of the appellation's power and finesse.\n",
      "\n",
      "Original Text:\n",
      "\n",
      "From a particular block with limestone soils, this is indeed a light, steely and minerally white wine, given nine months in French oak, only 17% of it new. It takes on that oak with subtle concentration, offering a touch of baked pineapple, peach and vanilla, ending in a bittersweet bite of Meyer lemon.\n",
      "\n",
      "\n",
      "Summarized text:\n",
      "\n",
      "From a particular block with limestone soils, this is indeed a light, steely and minerally white wine, given nine months in French oak, only 17% of it new. It takes on that oak with subtle concentration, offering a touch of baked pineapple, peach and vanilla, ending in a bittersweet bite of Meyer lemon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(test.shape[0]):\n",
    "    print(\"Original Text:\\n\")\n",
    "    print(descriptions[i])\n",
    "    print('\\n\\nSummarized text:\\n')\n",
    "    print(test_summary[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can notice, this method for summarization fares much better when the review consists of several sentences, instead of just 2–3 sentences. For a three sentence review, the summary will consist of two sentences, which shouldn’t be the case. Also, these three sentences may be conveying entirely different things, and omitting information from any one sentence is not desirable. Extractive methods normally are not preferred for summarization of short inputs, for this very reason. Supervised Seq2Seq models are better suited for this task. However in this case, reviews are generally longer in length and extractive methods work surprisingly well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
