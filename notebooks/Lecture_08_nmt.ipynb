{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4968,"status":"ok","timestamp":1649783494072,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"XVgqsEA10kLf"},"outputs":[],"source":["import collections\n","\n","\n","import string\n","import numpy as np\n","import pandas as pd\n","from random import randint\n","import nltk\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.utils import plot_model, to_categorical\n","from tensorflow.keras.models import Model, Sequential, load_model\n","from tensorflow.keras.layers import Dense, LSTM, GRU, Embedding, Input, TimeDistributed, Activation, RepeatVector, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","\n","from pickle import dump, load\n","\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1649783487132,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"C6r8H1Sq0kLi"},"outputs":[],"source":["\n","def load_data(path):\n","    \"\"\"\n","    Load dataset\n","    \"\"\"\n","    input_file = os.path.join(path)\n","    with open(input_file, \"r\") as f:\n","        data = f.read()\n","\n","    return data.split('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23865,"status":"ok","timestamp":1649783520259,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"re0GyPKLv3ON","outputId":"b791a06e-0062-4943-c334-d6f521250550"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1231,"status":"ok","timestamp":1649783844516,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"18_94_wE0kLi"},"outputs":[],"source":["df = pd.read_csv('data/eng-french.csv')\n","english_sentences = df['English'].to_list()\n","french_sentences = df['French'].to_list()\n"]},{"cell_type":"markdown","metadata":{"id":"z1YUeTYp0kLj"},"source":["Each line in clean_en file contains an English sentence with the respective Freench translation in each line of clean_fr file."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1649783848908,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"SX-VyJEB0kLk","outputId":"273f2895-37b6-439b-baea-04644742b1f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["English Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n","French Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n","\n","English Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n","French Line 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n","\n","English Line 3:  california is usually quiet during march , and it is usually hot in june .\n","French Line 3:  california est généralement calme en mars , et il est généralement chaud en juin .\n","\n"]}],"source":["for sample_i in range(3):\n","    print('English Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n","    print('French Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"wOb85S-Z0kLk"},"source":["Vocabulary\n","\n","The complexity of any machine translation problem (and NLP as a whole) is determined by the complexity of the vocabulary. A more complex vocabulary is a more complex problem.\n","\n","Let’s look at the complexity of the data set we’ll be working with."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1478,"status":"ok","timestamp":1649783975551,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"Z1IGhwaj0kLl"},"outputs":[],"source":["#  Let’s look at the complexity of the data set we’ll be working with.\n","english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n","french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":860,"status":"ok","timestamp":1649784127792,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"Jnv3qJsW0kLm","outputId":"445de18f-420c-4a4b-850b-ed6fa25cf08a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of English words: 1823250\n","Unique words in English: 227\n","10 Most common English words:\n","\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n","\n","Number of French words: 1961295\n","Unique words in French: 355\n","10 Most common French words:\n","\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"]}],"source":["print('Number of English words: {}'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n","print('Unique words in English: {}'.format(len(english_words_counter)))\n","print('10 Most common English words:')\n","print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n","print()\n","print('Number of French words: {}'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n","print('Unique words in French: {}'.format(len(french_words_counter)))\n","print('10 Most common French words:')\n","print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"]},{"cell_type":"markdown","metadata":{"id":"8llnCli60kLn"},"source":["### Pre-process\n","Dataset have been preprocessed already all we need is to do the following\n","#### 1. Tokenize\n","Turn each sentence into a sequence of words ids using Keras’s Tokenizer function.\n","\n","#### 2. Padding\n","Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the end of each sequence using Keras’s pad_sequences function."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1649785458109,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"SoMNDC480kLn"},"outputs":[],"source":["def tokenize(x):\n","    x_tk = Tokenizer(char_level = False)\n","    x_tk.fit_on_texts(x)\n","\n","    return x_tk.texts_to_sequences(x), x_tk\n","\n","\n","def pad(x, length=None):\n","    if length is None:\n","        length = max([len(sentence) for sentence in x])\n","    return pad_sequences(x, maxlen = length, padding = 'post')\n","\n","\n","def preprocess(x, y):\n","    preprocess_x, x_tk = tokenize(x)\n","    preprocess_y, y_tk = tokenize(y)\n","    preprocess_x = pad(preprocess_x)\n","    preprocess_y = pad(preprocess_y)\n","\n","    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n","    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n","    \n","    return preprocess_x, preprocess_y, x_tk, y_tk"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":382,"status":"ok","timestamp":1649785462966,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"qhEtkvsl0kLo"},"outputs":[],"source":["# text_sentences = english_sentences[:2]\n","# text_tokenized, text_tokenizer = tokenize(text_sentences)\n","\n","# print(text_tokenizer.word_index)\n","# print()\n","# for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n","#     print('Sequence {} in x'.format(sample_i + 1))\n","#     print('  Input:  {}'.format(sent))\n","#     print('  Output: {}'.format(token_sent))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1649785469173,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"p0YmnZdP0kLo"},"outputs":[],"source":["# # Pad Tokenized output\n","# test_pad = pad(text_tokenized)\n","# for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n","#     print('Sequence {} in x'.format(sample_i + 1))\n","#     print('  Input:  {}'.format(np.array(token_sent)))\n","#     print('  Output: {}'.format(pad_sent))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":10514,"status":"ok","timestamp":1649785481233,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"dKuws8kZ0kLp"},"outputs":[],"source":["preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n","    preprocess(english_sentences, french_sentences)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1649785485998,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"8ZXhgxAt0kLp"},"outputs":[],"source":["max_english_sequence_length = preproc_english_sentences.shape[1]\n","max_french_sequence_length = preproc_french_sentences.shape[1]\n","english_vocab_size = len(english_tokenizer.word_index)\n","french_vocab_size = len(french_tokenizer.word_index)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649785488869,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"ujMTxWrM0kLp","outputId":"ee922f01-edf8-4e8e-eae9-7fff72424842"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessed sentences\n","Max English sentence length: 15\n","Max French sentence length: 21\n","English vocabulary size: 199\n","French vocabulary size: 344\n"]}],"source":["print('Preprocessed sentences')\n","print(\"Max English sentence length:\", max_english_sequence_length)\n","print(\"Max French sentence length:\", max_french_sequence_length)\n","print(\"English vocabulary size:\", english_vocab_size)\n","print(\"French vocabulary size:\", french_vocab_size)"]},{"cell_type":"markdown","metadata":{"id":"6249Q6Fs0kLp"},"source":["## Models\n","We will experiment with various neural network architectures.  \n","    - Model 1 is a simple RNN  \n","    - Model 2 is a RNN with Embedding  \n","    - Model 3 is a Bidirectional RNN  \n","    - Model 4 is an Encoder-Decoder RNN  \n","\n","After experimenting with the four simple architectures, we will construct with a deeper model that designed to outperform all four models."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":543,"status":"ok","timestamp":1649787926413,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"lUhzI9f20kLq"},"outputs":[],"source":["def logits_to_text(logits, tokenizer):\n","    \"\"\"Convert NMT output to French text\"\"\"\n","    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n","    index_to_words[0] = '<PAD>'\n","    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"]},{"cell_type":"markdown","metadata":{"id":"IjdcYKXx0kLq"},"source":["#### Vanilla RNN\n","We are creating a basic RNN model which is a good baseline for sequence data that translate English to French."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1649787929349,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"OTj47cQr0kLq"},"outputs":[],"source":["def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n","    learning_rate = 1e-3\n","    input_seq = Input(input_shape[1:])\n","    rnn = GRU(64, return_sequences = True)(input_seq)\n","    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n","    model = Model(input_seq, Activation('softmax')(logits))\n","    model.compile(loss = sparse_categorical_crossentropy, \n","                 optimizer = Adam(learning_rate), \n","                 metrics = ['accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":35716,"status":"error","timestamp":1649788407257,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"X-ezrp360kLq","outputId":"c95ebd86-6a08-448b-f9d8-a03ddbe9dd91"},"outputs":[],"source":["# tests.test_simple_model(simple_model)\n","\n","tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))# Train the neural network\n","\n","simple_rnn_model = simple_model(\n","    tmp_x.shape,\n","    max_french_sequence_length,\n","    english_vocab_size,\n","    french_vocab_size)\n","# print(simple_rnn_model.summary())\n","simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1134,"status":"ok","timestamp":1649787984977,"user":{"displayName":"Lema Logamou Seknewna","userId":"11359632299962811515"},"user_tz":0},"id":"Bz0BI2G40kLq","outputId":"f70afbae-b0c6-4880-d72b-b1de1373b7ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["est est est est est est est est <PAD> <PAD> est <PAD> est <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"]}],"source":["# Print prediction(s)\n","print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"SWg6Vamp0kLq"},"source":["### Model 2: Embedding\n","Vanilla RNN model using word embedding."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r85D2DoR0kLr"},"outputs":[],"source":["def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n","    learning_rate = 1e-3\n","    rnn = GRU(64, return_sequences=True, activation=\"tanh\")\n","    \n","    embedding = Embedding(french_vocab_size, 64, input_length=input_shape[1]) \n","    logits = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"))\n","    \n","    model = Sequential()\n","    #em can only be used in first layer --> Keras Documentation\n","    model.add(embedding)\n","    model.add(rnn)\n","    model.add(logits)\n","    model.compile(loss=sparse_categorical_crossentropy,\n","                  optimizer=Adam(learning_rate),\n","                  metrics=['accuracy'])\n","    \n","    return model\n","\n","# tests.test_embed_model(embed_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swj3DyCT0kLr","outputId":"a87831bd-76f5-4d00-f933-d322b6163428"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","108/108 [==============================] - 12s 95ms/step - loss: 5.9686 - accuracy: 0.6355 - val_loss: 4.8060 - val_accuracy: 0.6482\n","Epoch 2/10\n","108/108 [==============================] - 10s 95ms/step - loss: 4.7530 - accuracy: 0.6470 - val_loss: 4.6795 - val_accuracy: 0.6482\n","Epoch 3/10\n","108/108 [==============================] - 10s 94ms/step - loss: 4.5375 - accuracy: 0.6797 - val_loss: 4.2939 - val_accuracy: 0.7034\n","Epoch 4/10\n","108/108 [==============================] - 10s 91ms/step - loss: 3.9487 - accuracy: 0.7368 - val_loss: 3.6298 - val_accuracy: 0.7635\n","Epoch 5/10\n","108/108 [==============================] - 10s 90ms/step - loss: 3.3807 - accuracy: 0.8032 - val_loss: 3.1455 - val_accuracy: 0.8482\n","Epoch 6/10\n","108/108 [==============================] - 10s 92ms/step - loss: 2.9748 - accuracy: 0.8662 - val_loss: 2.8280 - val_accuracy: 0.8887\n","Epoch 7/10\n","108/108 [==============================] - 10s 93ms/step - loss: 2.7068 - accuracy: 0.9076 - val_loss: 2.5833 - val_accuracy: 0.9346\n","Epoch 8/10\n","108/108 [==============================] - 10s 90ms/step - loss: 2.4615 - accuracy: 0.9616 - val_loss: 2.3381 - val_accuracy: 0.9874\n","Epoch 9/10\n","108/108 [==============================] - 10s 91ms/step - loss: 2.2251 - accuracy: 1.0090 - val_loss: 2.1144 - val_accuracy: 1.0343\n","Epoch 10/10\n","108/108 [==============================] - 10s 91ms/step - loss: 2.0196 - accuracy: 1.0545 - val_loss: 1.9318 - val_accuracy: 1.0779\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2aaf08640>"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n","embeded_model = embed_model(\n","    tmp_x.shape,\n","    max_french_sequence_length,\n","    english_vocab_size,\n","    french_vocab_size)\n","    \n","embeded_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRCkSboI0kLr","outputId":"ae0fd1e2-56c0-46c9-e40a-afd6eef4424f"},"outputs":[{"name":"stdout","output_type":"stream","text":["new jersey est parfois parfois en l' et et il il est en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"]}],"source":["print(logits_to_text(embeded_model.predict(tmp_x[:1])[0], french_tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"VcoXL9O-0kLr"},"source":["#### Model 3: Bidirectional RNNs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uN9tdlog0kLr"},"outputs":[],"source":["def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n","   \n","    learning_rate = 1e-3\n","    model = Sequential()\n","    model.add(Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), \n","                           input_shape = input_shape[1:]))\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n","    model.compile(loss = sparse_categorical_crossentropy, \n","                 optimizer = Adam(learning_rate), \n","                 metrics = ['accuracy'])\n","    return model\n","\n","# tests.test_bd_model(bd_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rm3mNfh-0kLr","outputId":"13fba063-4695-429b-a0c0-30d3f0896073"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","108/108 [==============================] - 16s 131ms/step - loss: 4.3289 - accuracy: 0.7713 - val_loss: 3.0960 - val_accuracy: 0.8537\n","Epoch 2/20\n","108/108 [==============================] - 13s 124ms/step - loss: 2.8902 - accuracy: 0.8797 - val_loss: 2.5488 - val_accuracy: 0.9258\n","Epoch 3/20\n","108/108 [==============================] - 13s 123ms/step - loss: 2.5190 - accuracy: 0.9367 - val_loss: 2.3323 - val_accuracy: 0.9660\n","Epoch 4/20\n","108/108 [==============================] - 14s 131ms/step - loss: 2.3315 - accuracy: 0.9592 - val_loss: 2.2109 - val_accuracy: 0.9815\n","Epoch 5/20\n","108/108 [==============================] - 14s 125ms/step - loss: 2.2184 - accuracy: 0.9755 - val_loss: 2.1515 - val_accuracy: 0.9855\n","Epoch 6/20\n","108/108 [==============================] - 13s 123ms/step - loss: 2.1376 - accuracy: 0.9901 - val_loss: 2.0905 - val_accuracy: 0.9969\n","Epoch 7/20\n","108/108 [==============================] - 13s 120ms/step - loss: 2.0760 - accuracy: 1.0026 - val_loss: 2.0507 - val_accuracy: 1.0008\n","Epoch 8/20\n","108/108 [==============================] - 13s 121ms/step - loss: 2.0245 - accuracy: 1.0120 - val_loss: 2.0292 - val_accuracy: 0.9953\n","Epoch 9/20\n","108/108 [==============================] - 13s 122ms/step - loss: 1.9758 - accuracy: 1.0213 - val_loss: 2.0032 - val_accuracy: 0.9946\n","Epoch 10/20\n","108/108 [==============================] - 13s 123ms/step - loss: 1.9342 - accuracy: 1.0295 - val_loss: 1.9864 - val_accuracy: 0.9931\n","Epoch 11/20\n","108/108 [==============================] - 13s 124ms/step - loss: 1.8980 - accuracy: 1.0369 - val_loss: 1.9839 - val_accuracy: 0.9934\n","Epoch 12/20\n","108/108 [==============================] - 13s 122ms/step - loss: 1.8687 - accuracy: 1.0421 - val_loss: 1.9789 - val_accuracy: 0.9928\n","Epoch 13/20\n","108/108 [==============================] - 14s 126ms/step - loss: 1.8381 - accuracy: 1.0490 - val_loss: 1.9893 - val_accuracy: 0.9876\n","Epoch 14/20\n","108/108 [==============================] - 13s 122ms/step - loss: 1.8225 - accuracy: 1.0535 - val_loss: 1.9924 - val_accuracy: 0.9857\n","Epoch 15/20\n","108/108 [==============================] - 13s 120ms/step - loss: 1.7957 - accuracy: 1.0592 - val_loss: 2.0087 - val_accuracy: 0.9848\n","Epoch 16/20\n","108/108 [==============================] - 13s 125ms/step - loss: 1.7725 - accuracy: 1.0628 - val_loss: 1.9917 - val_accuracy: 0.9909\n","Epoch 17/20\n","108/108 [==============================] - 13s 124ms/step - loss: 1.7520 - accuracy: 1.0660 - val_loss: 2.0242 - val_accuracy: 0.9874\n","Epoch 18/20\n","108/108 [==============================] - 13s 124ms/step - loss: 1.7335 - accuracy: 1.0691 - val_loss: 2.0675 - val_accuracy: 0.9803\n","Epoch 19/20\n","108/108 [==============================] - 13s 124ms/step - loss: 1.7123 - accuracy: 1.0722 - val_loss: 2.0650 - val_accuracy: 0.9820\n","Epoch 20/20\n","108/108 [==============================] - 14s 125ms/step - loss: 1.6936 - accuracy: 1.0756 - val_loss: 2.1032 - val_accuracy: 0.9738\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2a8abdfd0>"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n","bidi_model = bd_model(\n","    tmp_x.shape,\n","    preproc_french_sentences.shape[1],\n","    len(english_tokenizer.word_index)+1,\n","    len(french_tokenizer.word_index)+1)\n","bidi_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glrPJySn0kLr","outputId":"7a1c97ee-fdc4-4aac-aedf-361458c2653a"},"outputs":[{"name":"stdout","output_type":"stream","text":["new jersey est parfois froid au printemps mais il est agréable en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"]}],"source":["print(logits_to_text(bidi_model.predict(tmp_x[:1])[0], french_tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"PRv-JoD60kLs"},"source":["#### Model 4: Encoder-Decoder\n","The encoder creates a matrix representation of the sentence. The decoder takes this matrix as input and predicts the translation as output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CXez4wM0kLs"},"outputs":[],"source":["def encoder_decoder_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n","  \n","    learning_rate = 1e-3\n","    model = Sequential()\n","    model.add(GRU(128, input_shape = input_shape[1:], return_sequences = False))\n","    model.add(RepeatVector(output_sequence_length))\n","    model.add(GRU(128, return_sequences = True))\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n","    \n","    model.compile(loss = sparse_categorical_crossentropy, \n","                 optimizer = Adam(learning_rate), \n","                 metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bO9SVFFo0kLs","outputId":"9d00cf63-f6b3-4bc7-a82d-260328fa514a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","108/108 [==============================] - 14s 118ms/step - loss: 4.8647 - accuracy: 0.6834 - val_loss: 4.0311 - val_accuracy: 0.7524\n","Epoch 2/20\n","108/108 [==============================] - 12s 111ms/step - loss: 3.7915 - accuracy: 0.7735 - val_loss: 3.6560 - val_accuracy: 0.7731\n","Epoch 3/20\n","108/108 [==============================] - 12s 108ms/step - loss: 3.5203 - accuracy: 0.7933 - val_loss: 3.3258 - val_accuracy: 0.8021\n","Epoch 4/20\n","108/108 [==============================] - 12s 107ms/step - loss: 3.1711 - accuracy: 0.8226 - val_loss: 3.0564 - val_accuracy: 0.8363\n","Epoch 5/20\n","108/108 [==============================] - 12s 109ms/step - loss: 2.9607 - accuracy: 0.8532 - val_loss: 2.8660 - val_accuracy: 0.8731\n","Epoch 6/20\n","108/108 [==============================] - 12s 109ms/step - loss: 2.8015 - accuracy: 0.8777 - val_loss: 2.7364 - val_accuracy: 0.8812\n","Epoch 7/20\n","108/108 [==============================] - 12s 108ms/step - loss: 2.6855 - accuracy: 0.8903 - val_loss: 2.6368 - val_accuracy: 0.9000\n","Epoch 8/20\n","108/108 [==============================] - 12s 107ms/step - loss: 2.6037 - accuracy: 0.9031 - val_loss: 2.5632 - val_accuracy: 0.9125\n","Epoch 9/20\n","108/108 [==============================] - 11s 106ms/step - loss: 2.5300 - accuracy: 0.9165 - val_loss: 2.4941 - val_accuracy: 0.9242\n","Epoch 10/20\n","108/108 [==============================] - 11s 106ms/step - loss: 2.4594 - accuracy: 0.9276 - val_loss: 2.4321 - val_accuracy: 0.9307\n","Epoch 11/20\n","108/108 [==============================] - 12s 108ms/step - loss: 2.3967 - accuracy: 0.9415 - val_loss: 2.3643 - val_accuracy: 0.9480\n","Epoch 12/20\n","108/108 [==============================] - 12s 107ms/step - loss: 2.3404 - accuracy: 0.9518 - val_loss: 2.3210 - val_accuracy: 0.9529\n","Epoch 13/20\n","108/108 [==============================] - 11s 106ms/step - loss: 2.2897 - accuracy: 0.9627 - val_loss: 2.2642 - val_accuracy: 0.9660\n","Epoch 14/20\n","108/108 [==============================] - 12s 108ms/step - loss: 2.2464 - accuracy: 0.9714 - val_loss: 2.2218 - val_accuracy: 0.9788\n","Epoch 15/20\n","108/108 [==============================] - 12s 109ms/step - loss: 2.2167 - accuracy: 0.9762 - val_loss: 2.1898 - val_accuracy: 0.9862\n","Epoch 16/20\n","108/108 [==============================] - 12s 108ms/step - loss: 2.1839 - accuracy: 0.9822 - val_loss: 2.1634 - val_accuracy: 0.9914\n","Epoch 17/20\n","108/108 [==============================] - 12s 108ms/step - loss: 2.1594 - accuracy: 0.9874 - val_loss: 2.1421 - val_accuracy: 0.9940\n","Epoch 18/20\n","108/108 [==============================] - 12s 108ms/step - loss: 2.1371 - accuracy: 0.9917 - val_loss: 2.1215 - val_accuracy: 0.9964\n","Epoch 19/20\n","108/108 [==============================] - 12s 110ms/step - loss: 2.1129 - accuracy: 0.9962 - val_loss: 2.1081 - val_accuracy: 0.9972\n","Epoch 20/20\n","108/108 [==============================] - 12s 110ms/step - loss: 2.0965 - accuracy: 0.9982 - val_loss: 2.0795 - val_accuracy: 1.0023\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2a892aeb0>"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# tests.test_encdec_model(encdec_model)\n","tmp_x = pad(preproc_english_sentences)\n","tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[1], 1))\n","encodeco_model = encoder_decoder_model(\n","    tmp_x.shape,\n","    preproc_french_sentences.shape[1],\n","    len(english_tokenizer.word_index)+1,\n","    len(french_tokenizer.word_index)+1)\n","\n","encodeco_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gU87O5Yb0kLs","outputId":"37c679b2-b9cc-467c-c85d-2b03e2d7523d"},"outputs":[{"name":"stdout","output_type":"stream","text":["new jersey est jamais en en mois et il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"]}],"source":["print(logits_to_text(encodeco_model.predict(tmp_x[:1])[0], french_tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"zqrOIkxE0kLs"},"source":["#### Model 5: Stacked Model\n","Create a model_final that incorporates embedding and a bidirectional RNN into one model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4t8-YIX0kLs"},"outputs":[],"source":["def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n","  \n","    model = Sequential()\n","    model.add(Embedding(input_dim=english_vocab_size,output_dim=128,input_length=input_shape[1]))\n","    model.add(Bidirectional(GRU(256,return_sequences=False)))\n","    model.add(RepeatVector(output_sequence_length))\n","    model.add(Bidirectional(GRU(256,return_sequences=True)))\n","    model.add(TimeDistributed(Dense(french_vocab_size,activation='softmax')))\n","    learning_rate = 0.005\n","    \n","    model.compile(loss = sparse_categorical_crossentropy, \n","                 optimizer = Adam(learning_rate), \n","                 metrics = ['accuracy'])\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkbZOnoi0kLs","outputId":"169ba838-ce34-42e9-ef39-4b9ac4f83b1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","108/108 [==============================] - 55s 487ms/step - loss: 3.4857 - accuracy: 0.7926 - val_loss: 2.4790 - val_accuracy: 0.9310\n","Epoch 2/20\n","108/108 [==============================] - 51s 475ms/step - loss: 1.8705 - accuracy: 1.0751 - val_loss: 1.4621 - val_accuracy: 1.1693\n","Epoch 3/20\n","108/108 [==============================] - 51s 468ms/step - loss: 1.2366 - accuracy: 1.2225 - val_loss: 0.9832 - val_accuracy: 1.2925\n","Epoch 4/20\n","108/108 [==============================] - 50s 463ms/step - loss: 0.7851 - accuracy: 1.3504 - val_loss: 0.5969 - val_accuracy: 1.4059\n","Epoch 5/20\n","108/108 [==============================] - 52s 481ms/step - loss: 0.5138 - accuracy: 1.4313 - val_loss: 0.4383 - val_accuracy: 1.4553\n","Epoch 6/20\n","108/108 [==============================] - 52s 483ms/step - loss: 0.4046 - accuracy: 1.4638 - val_loss: 0.4086 - val_accuracy: 1.4624\n","Epoch 7/20\n","108/108 [==============================] - 56s 515ms/step - loss: 0.3672 - accuracy: 1.4761 - val_loss: 0.3250 - val_accuracy: 1.4905\n","Epoch 8/20\n","108/108 [==============================] - 51s 470ms/step - loss: 0.3419 - accuracy: 1.4848 - val_loss: 0.3256 - val_accuracy: 1.4899\n","Epoch 9/20\n","108/108 [==============================] - 53s 492ms/step - loss: 0.3051 - accuracy: 1.4960 - val_loss: 0.8287 - val_accuracy: 1.3702\n","Epoch 10/20\n","108/108 [==============================] - 53s 487ms/step - loss: 0.5795 - accuracy: 1.4154 - val_loss: 0.4684 - val_accuracy: 1.4484\n","Epoch 11/20\n","108/108 [==============================] - 63s 581ms/step - loss: 0.4769 - accuracy: 1.4439 - val_loss: 0.6931 - val_accuracy: 1.3785\n","Epoch 12/20\n","108/108 [==============================] - 74s 673ms/step - loss: 0.6443 - accuracy: 1.3928 - val_loss: 0.6249 - val_accuracy: 1.4028\n","Epoch 13/20\n","108/108 [==============================] - 72s 660ms/step - loss: 0.6311 - accuracy: 1.3970 - val_loss: 0.6503 - val_accuracy: 1.3910\n","Epoch 14/20\n","108/108 [==============================] - 82s 761ms/step - loss: 0.7783 - accuracy: 1.3538 - val_loss: 0.8797 - val_accuracy: 1.3269\n","Epoch 15/20\n","108/108 [==============================] - 69s 629ms/step - loss: 1.0689 - accuracy: 1.2767 - val_loss: 1.1405 - val_accuracy: 1.2557\n","Epoch 16/20\n","108/108 [==============================] - 68s 627ms/step - loss: 0.9661 - accuracy: 1.3016 - val_loss: 1.1095 - val_accuracy: 1.2559\n","Epoch 17/20\n","108/108 [==============================] - 77s 716ms/step - loss: 1.0097 - accuracy: 1.2888 - val_loss: 1.0349 - val_accuracy: 1.2811\n","Epoch 18/20\n","108/108 [==============================] - 77s 702ms/step - loss: 0.9766 - accuracy: 1.2968 - val_loss: 0.9286 - val_accuracy: 1.3092\n","Epoch 19/20\n","108/108 [==============================] - 72s 663ms/step - loss: 0.9370 - accuracy: 1.3060 - val_loss: 1.1137 - val_accuracy: 1.2554\n","Epoch 20/20\n","108/108 [==============================] - 68s 627ms/step - loss: 1.0432 - accuracy: 1.2814 - val_loss: 1.0049 - val_accuracy: 1.2898\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x311bbfc70>"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["tmp_X = pad(preproc_english_sentences)\n","model = model_final(tmp_X.shape,\n","                    preproc_french_sentences.shape[1],\n","                    len(english_tokenizer.word_index)+1,\n","                    len(french_tokenizer.word_index)+1)\n","    \n","model.fit(tmp_X, preproc_french_sentences, batch_size = 1024, epochs = 20, validation_split = 0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKYl-NvC0kLt"},"outputs":[],"source":["def final_predictions(sentence, x, y, x_tk, y_tk):\n","\n","    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n","    y_id_to_word[0] = '<PAD>'\n","    \n","    sentence = [x_tk.word_index[word] for word in sentence.split()]\n","    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n","    sentences = np.array([sentence[0], x[0]])\n","    predictions = model.predict(sentences, len(sentences))\n","    \n","    print('Sample 1:')\n","    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n","    \n","    print('Sample 2:')\n","    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Sample 1:\n","il a conduit un vieux <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","\n","Sample 2:\n","new jersey est parfois calme pendant l'automne et il est en en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16LGGVtn0kLt","outputId":"a3301c18-d496-46fa-b7ba-c08027dda68d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Target: Il a vu un vieux camion jaune\n","WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x32e838d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Sample 1:\n","il a conduit un vieux <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Sample 2:\n","new jersey est parfois calme pendant l'automne et il est en en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"]}],"source":["sentence = 'he saw a old yellow truck'\n","print('Target: Il a vu un vieux camion jaune')\n","\n","final_predictions(sentence, preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"]}],"metadata":{"colab":{"name":"Lecture_06_nmt.ipynb","provenance":[]},"interpreter":{"hash":"b4c31a2617073d188e5f2a97711a94f6620d1a14e3d1ab03025bd2b5e3175c60"},"kernelspec":{"display_name":"Python 3.9.10 ('nlp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
