{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling and Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is a common NLP task, which attempts to find the topics within a text document. Topic modeling is an unsupervised approach, and topic modeling only gives you an idea of which words frequently occur. It is then up to you to deduce the topic having seen the frequently and co-occurring words.\n",
    "\n",
    "One of the primary applications of natural language processing is to automatically extract what topics people are discussing from large volumes of text. Some examples of large text could be feeds from social media, customer reviews of hotels, movies, etc, user feedbacks, news stories, e-mails of customer complaints etc.\n",
    "\n",
    "Knowing what people are talking about and understanding their problems and opinions is highly valuable to businesses, administrators, political campaigns. And it’s really hard to manually read through such large volumes and compile the topics.\n",
    "\n",
    "Thus is required an automated algorithm that can read through the text documents and automatically output the topics discussed.\n",
    "\n",
    "In this tutorial, we will take a real example of the ’20 Newsgroups’ dataset and use LDA to extract the naturally discussed topics.\n",
    "\n",
    "I will be using the Latent Dirichlet Allocation (LDA) from Gensim package along with the Mallet’s implementation (via Gensim). Mallet has an efficient implementation of the LDA. It is known to run faster and gives better topics segregation.\n",
    "\n",
    "We will also extract the volume and percentage contribution of each topic to get an idea of how important a topic is. \n",
    "\n",
    "\n",
    "LDA’s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion.\n",
    "\n",
    "Once you provide the algorithm with the number of topics, all it does it to rearrange the topics distribution within the documents and keywords distribution within the topics to obtain a good composition of topic-keywords distribution.\n",
    "\n",
    "When I say topic, what is it actually and how it is represented?\n",
    "\n",
    "A topic is nothing but a collection of dominant keywords that are typical representatives. Just by looking at the keywords, you can identify what the topic is all about.\n",
    "\n",
    "The following are key factors to obtaining good segregation topics:\n",
    "\n",
    "    The quality of text processing.\n",
    "    The variety of topics the text talks about.\n",
    "    The choice of topic modeling algorithm.\n",
    "    The number of topics fed to the algorithm.\n",
    "    The algorithms tuning parameters.\n",
    "\n",
    "\n",
    "\n",
    "#### Assumptions:\n",
    "\n",
    "    1. Each document is just a collection of words or a “bag of words”. Thus, the order of the words and the grammatical role of the words (subject, object, verbs, ..) are not considered in the model.  \n",
    "    \n",
    "    2. Words like am/is/are/of/a/the/but/… don’t carry any information about the “topics” and therefore can be eliminated from the documents as a preprocessing step. In fact, we can eliminate words that occur in at least %80 ~ %90 of the documents, without losing any information. For example, if our corpus contains only medical documents, words like human, body, health, etc might be present in most of the documents and hence can be removed as they don’t add any specific information which would make the document stand out.  \n",
    "\n",
    "    3. We know beforehand how many topics we want. ‘k’ is pre-decided.  \n",
    "\n",
    "    4. All topic assignments except for the current word in question are correct, and then updating the assignment of the current word using our model of how documents are generated  \n",
    "\n",
    "\n",
    "#### How does LDA work?\n",
    "There are 2 parts in LDA:\n",
    "\n",
    "    The words that belong to a document, that we already know.\n",
    "    The words that belong to a topic or the probability of words belonging into a topic, that we need to calculate.\n",
    "\n",
    "The Algorithm to find the latter\n",
    "\n",
    "    Go through each document and randomly assign each word in the document to one of k topics (k is chosen beforehand).\n",
    "    For each document d, go through each word w and compute:  \n",
    "        1. p(topic t | document d):  \n",
    "            - the proportion of words in document d that are assigned to topic t. Tries to capture how many words belong to the topic t for a given document d. Excluding the current word.  \n",
    "            - If a lot of words from d belongs to t, it is more probable that word w belongs to t. ( #words in d with t +alpha/ #words in d with any topic+ k*alpha)\n",
    "        2. p(word w| topic t):  \n",
    "            - the proportion of assignments to topic t over all documents that come from this word w. Tries to capture how many documents are in topic t because of word w.  \n",
    "\n",
    "            - LDA represents documents as a mixture of topics. Similarly, a topic is a mixture of words. If a word has high probability of being in a topic, all the documents having w will be more strongly associated with t as well. Similarly, if w is not very probable to be in t, the documents which contain the w will be having very low probability of being in t, because rest of the words in d will belong to some other topic and hence d will have a higher probability for those topic. So even if w gets added to t, it won’t be bringing many such documents to t.\n",
    "\n",
    "    Update the probability for the word w belonging to topic t, as  \n",
    "            p(word w with topic t) = p(topic t | document d) * p(word w | topic t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- For this exercise we use the news headlines published over a period of eighteen years from Australian sources ABC from [kaggle](https://www.kaggle.com/therohk/million-headlines/data) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "data = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
      " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
      " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
      " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
      " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
      " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "\n",
       "            target_names  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select a subset\n",
    "data = data.sample(n = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data_text = data.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data_text = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data_text]\n",
    "\n",
    "# Remove new line characters\n",
    "data_text = [re.sub('\\s+', ' ', sent) for sent in data_text]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data_text = [re.sub(\"\\'\", \"\", sent) for sent in data_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (Doug Loss) Subject: Re: Crazy? or just Imaginitive? Organization: '\n",
      " 'Electrical and Computer Engineering, Carnegie Mellon Lines: 22 In article '\n",
      " 'writes: > >Unfortunately H. Beam Piper killed him self just weeks short of '\n",
      " 'having his >first book published, and have his ideas see light.. Such a '\n",
      " 'waste. > > Piper lived in my town (Williamsport, PA) when he killed himself. '\n",
      " 'It was in the early 60s. He had had more than a few books published by that '\n",
      " 'time, but he was down on his luck financially. Rumor was that he was hunting '\n",
      " 'urban pigeons with birdshot for food. He viewed himself as a resourceful '\n",
      " 'man, and (IMO) decided to check out gracefully if he couldnt support '\n",
      " 'himself. The worst part is that John Campbell, the long-time editor of '\n",
      " 'Astounding/Analog SF magazine had cut a check for Pipers most recent story, '\n",
      " 'and said check was in the mail. If Campbell had known Pipers straits, Im '\n",
      " 'sure he would have phoned to say hang on. Campbell was like that. I wish it '\n",
      " 'had happened differently. I always enjoyed Pipers stuff. Doug Loss ']\n"
     ]
    }
   ],
   "source": [
    "pprint(data_text[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize words and Clean-up text\n",
    "\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
    "\n",
    "Gensim’s simple_preprocess() is great for this. Additionally I have set deacc=True to remove the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spacy language model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customized stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New stop words list \n",
    "customize_stop_words = [\n",
    "    'doi', 'preprint', 'copyright', 'org', 'https', 'et', 'al', 'author', 'figure', 'table', 'e-mail', 'file'\n",
    "    'rights', 'reserved', 'permission', 'use', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', 'al.', 'Elsevier', 'PMC', 'CZI',\n",
    "    '-PRON-', 'usually'\n",
    "]\n",
    "\n",
    "# Mark them as stop words\n",
    "for w in customize_stop_words:\n",
    "    nlp.vocab[w].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check word frequencys\n",
    "def spacy_tokenizer(sentence):\n",
    "    return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, min_df=2)\n",
    "data_vectorized = vectorizer.fit_transform(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent words\n",
    "word_count = pd.DataFrame({'word': vectorizer.get_feature_names(), 'count': np.asarray(data_vectorized.sum(axis=0))[0]})\n",
    "word_count.sort_values('count', ascending=False).set_index('word')[:20].sort_values('count', ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sentences to words\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'andrew', 'byler', 'subject', 're', 'revelations', 'babylon', 'organization', 'freshman', 'civil', 'engineering', 'carnegie', 'mellon', 'pittsburgh', 'pa', 'lines', 'hal', 'heydt', 'writes', 'that', 'was', 'only', 'the', 'fall', 'of', 'the', 'western', 'empire', 'the', 'eastern', 'empire', 'continued', 'for', 'another', 'years', 'and', 'key', 'element', 'in', 'its', 'fall', 'was', 'the', 'christian', 'sack', 'of', 'constantinople', 'note', 'that', 'said', 'the', 'fall', 'of', 'rome', 'not', 'of', 'the', 'empire', 'the', 'roman', 'empire', 'lasted', 'until', 'with', 'its', 'transfered', 'capital', 'in', 'constantinople', 'the', 'main', 'reason', 'for', 'its', 'fall', 'was', 'not', 'so', 'much', 'the', 'sack', 'of', 'constantinople', 'by', 'the', 'men', 'of', 'the', 'th', 'crusade', 'who', 'were', 'not', 'christians', 'they', 'had', 'been', 'excommunicated', 'down', 'to', 'the', 'last', 'man', 'after', 'attacking', 'the', 'christian', 'city', 'of', 'zara', 'in', 'croatia', 'but', 'rather', 'the', 'disastorous', 'defeat', 'in', 'the', 'battle', 'of', 'mazinkert', 'after', 'the', 'turks', 'breached', 'the', 'frontier', 'it', 'was', 'only', 'matter', 'of', 'time', 'before', 'the', 'empire', 'fell', 'the', 'inability', 'of', 'the', 'empire', 'to', 'hold', 'onto', 'the', 'rim', 'of', 'anatolia', 'with', 'the', 'ottomans', 'and', 'rum', 'seljuks', 'in', 'the', 'middle', 'should', 'be', 'quite', 'obvious', 'to', 'any', 'student', 'of', 'history', 'the', 'sack', 'of', 'constantinople', 'only', 'hastened', 'the', 'inevitable', 'along', 'for', 'if', 'the', 'greeks', 'had', 'wanted', 'to', 'save', 'their', 'empire', 'why', 'would', 'they', 'not', 'cooperate', 'with', 'the', 'crusaders', 'when', 'they', 'came', 'to', 'do', 'battle', 'with', 'the', 'saracens', 'in', 'the', 'st', 'rd', 'crusades', 'because', 'of', 'their', 'obstinacy', 'over', 'cooperating', 'with', 'people', 'they', 'considered', 'heretics', 'even', 'though', 'those', 'heretics', 'were', 'fighting', 'for', 'the', 'cause', 'of', 'the', 'empire', 'and', 'christendom', 'in', 'doing', 'battle', 'with', 'the', 'turkish', 'hordes', 'in', 'anatolia', 'edessa', 'lebanon', 'palastine', 'and', 'syria', 'the', 'some', 'hordes', 'who', 'were', 'to', 'later', 'sack', 'constantinople', 'and', 'overrun', 'third', 'of', 'europe', 'the', 'balkans', 'hungary', 'the', 'ukraine', 'the', 'caucasus', 'etc', 'andy', 'byler']]\n"
     ]
    }
   ],
   "source": [
    "data_words = list(sent_to_words(data_text))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bigram and Trigram Models\n",
    "\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.\n",
    "\n",
    "Gensim’s Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold. The higher the values of these param, the harder it is for words to be combined to bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'andrew', 'byler', 'subject_re', 'revelations', 'babylon', 'organization', 'freshman', 'civil', 'engineering', 'carnegie_mellon', 'pittsburgh_pa', 'lines', 'hal', 'heydt', 'writes', 'that', 'was', 'only', 'the', 'fall', 'of', 'the', 'western', 'empire', 'the', 'eastern', 'empire', 'continued', 'for', 'another', 'years', 'and', 'key', 'element', 'in', 'its', 'fall', 'was', 'the', 'christian', 'sack', 'of', 'constantinople', 'note', 'that', 'said', 'the', 'fall', 'of', 'rome', 'not', 'of', 'the', 'empire', 'the', 'roman', 'empire', 'lasted', 'until', 'with', 'its', 'transfered', 'capital', 'in', 'constantinople', 'the', 'main', 'reason', 'for', 'its', 'fall', 'was', 'not', 'so', 'much', 'the', 'sack', 'of', 'constantinople', 'by', 'the', 'men', 'of', 'the', 'th', 'crusade', 'who', 'were', 'not', 'christians', 'they', 'had', 'been', 'excommunicated', 'down', 'to', 'the', 'last', 'man', 'after', 'attacking', 'the', 'christian', 'city', 'of', 'zara', 'in', 'croatia', 'but', 'rather', 'the', 'disastorous', 'defeat', 'in', 'the', 'battle', 'of', 'mazinkert', 'after', 'the', 'turks', 'breached', 'the', 'frontier', 'it', 'was', 'only', 'matter', 'of', 'time', 'before', 'the', 'empire', 'fell', 'the', 'inability', 'of', 'the', 'empire', 'to', 'hold', 'onto', 'the', 'rim', 'of', 'anatolia', 'with', 'the', 'ottomans', 'and', 'rum', 'seljuks', 'in', 'the', 'middle', 'should', 'be', 'quite', 'obvious', 'to', 'any', 'student', 'of', 'history', 'the', 'sack', 'of', 'constantinople', 'only', 'hastened', 'the', 'inevitable', 'along', 'for', 'if', 'the', 'greeks', 'had', 'wanted', 'to', 'save', 'their', 'empire', 'why', 'would', 'they', 'not', 'cooperate', 'with', 'the', 'crusaders', 'when', 'they', 'came', 'to', 'do', 'battle', 'with', 'the', 'saracens', 'in', 'the', 'st', 'rd', 'crusades', 'because', 'of', 'their', 'obstinacy', 'over', 'cooperating', 'with', 'people', 'they', 'considered', 'heretics', 'even', 'though', 'those', 'heretics', 'were', 'fighting', 'for', 'the', 'cause', 'of', 'the', 'empire', 'and', 'christendom', 'in', 'doing', 'battle', 'with', 'the', 'turkish', 'hordes', 'in', 'anatolia', 'edessa', 'lebanon', 'palastine', 'and', 'syria', 'the', 'some', 'hordes', 'who', 'were', 'to', 'later', 'sack', 'constantinople', 'and', 'overrun', 'third', 'of', 'europe', 'the', 'balkans', 'hungary', 'the', 'ukraine', 'the', 'caucasus', 'etc', 'andy', 'byler']\n"
     ]
    }
   ],
   "source": [
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords, Make Bigrams and Lemmatize\n",
    "\n",
    "The bigrams model is ready. Let’s define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['revelation', 'freshman', 'civil', 'engineering', 'carnegie_mellon', 'line', 'hal', 'heydt', 'write', 'fall', 'western', 'empire', 'eastern', 'empire', 'continue', 'year', 'key', 'element', 'fall', 'note', 'say', 'empire', 'last', 'transfered', 'capital', 'constantinople', 'main', 'reason', 'fall', 'much', 'sack', 'constantinople', 'man', 'crusade', 'christian', 'excommunicate', 'last', 'man', 'attack', 'christian', 'city', 'rather', 'disastorous', 'defeat', 'battle', 'mazinkert', 'turk', 'breach', 'frontier', 'matter', 'time', 'empire', 'fall', 'inability', 'empire', 'hold', 'seljuk', 'middle', 'quite', 'obvious', 'student', 'history', 'sack', 'constantinople', 'hasten', 'inevitable', 'want', 'save', 'empire', 'cooperate', 'crusader', 'come', 'battle', 'crusade', 'obstinacy', 'cooperate', 'people', 'consider', 'heretic', 'even', 'heretic', 'fighting', 'cause', 'empire', 'christendom', 'battle', 'turkish', 'horde', 'horde', 'later', 'sack', 'constantinople', 'balkan', 'hungary', 'ukraine', 'caucasus']]\n"
     ]
    }
   ],
   "source": [
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dictionary and Corpus needed for Topic Modeling\n",
    "\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus.  \n",
    "\n",
    "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
    "\n",
    "For example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n",
    "\n",
    "This is used as the input by the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 3), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 1), (16, 2), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 7), (24, 1), (25, 1), (26, 1), (27, 4), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 2), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 3), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attack'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('attack', 1),\n",
       "  ('balkan', 1),\n",
       "  ('battle', 3),\n",
       "  ('breach', 1),\n",
       "  ('capital', 1),\n",
       "  ('carnegie_mellon', 1),\n",
       "  ('caucasus', 1),\n",
       "  ('cause', 1),\n",
       "  ('christendom', 1),\n",
       "  ('christian', 2),\n",
       "  ('city', 1),\n",
       "  ('civil', 1),\n",
       "  ('come', 1),\n",
       "  ('consider', 1),\n",
       "  ('constantinople', 4),\n",
       "  ('continue', 1),\n",
       "  ('cooperate', 2),\n",
       "  ('crusade', 2),\n",
       "  ('crusader', 1),\n",
       "  ('defeat', 1),\n",
       "  ('disastorous', 1),\n",
       "  ('eastern', 1),\n",
       "  ('element', 1),\n",
       "  ('empire', 7),\n",
       "  ('engineering', 1),\n",
       "  ('even', 1),\n",
       "  ('excommunicate', 1),\n",
       "  ('fall', 4),\n",
       "  ('fighting', 1),\n",
       "  ('freshman', 1),\n",
       "  ('frontier', 1),\n",
       "  ('hal', 1),\n",
       "  ('hasten', 1),\n",
       "  ('heretic', 2),\n",
       "  ('heydt', 1),\n",
       "  ('history', 1),\n",
       "  ('hold', 1),\n",
       "  ('horde', 2),\n",
       "  ('hungary', 1),\n",
       "  ('inability', 1),\n",
       "  ('inevitable', 1),\n",
       "  ('key', 1),\n",
       "  ('last', 2),\n",
       "  ('later', 1),\n",
       "  ('line', 1),\n",
       "  ('main', 1),\n",
       "  ('man', 2),\n",
       "  ('matter', 1),\n",
       "  ('mazinkert', 1),\n",
       "  ('middle', 1),\n",
       "  ('much', 1),\n",
       "  ('note', 1),\n",
       "  ('obstinacy', 1),\n",
       "  ('obvious', 1),\n",
       "  ('people', 1),\n",
       "  ('quite', 1),\n",
       "  ('rather', 1),\n",
       "  ('reason', 1),\n",
       "  ('revelation', 1),\n",
       "  ('sack', 3),\n",
       "  ('save', 1),\n",
       "  ('say', 1),\n",
       "  ('seljuk', 1),\n",
       "  ('student', 1),\n",
       "  ('time', 1),\n",
       "  ('transfered', 1),\n",
       "  ('turk', 1),\n",
       "  ('turkish', 1),\n",
       "  ('ukraine', 1),\n",
       "  ('want', 1),\n",
       "  ('western', 1),\n",
       "  ('write', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Topic Model\n",
    "\n",
    "We have everything required to train the LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well.\n",
    "\n",
    "Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior.\n",
    "\n",
    "chunksize is the number of documents to be used in each training chunk. update_every determines how often the model parameters should be updated and passes is the total number of training passes.  \n",
    "\n",
    "LDA has 3 important parameters\n",
    "    - alpha: document-topic density factor  \n",
    "    - beta: word density in a topic  \n",
    "    - k: number of topics to cluster the document into  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the topics in LDA model\n",
    "\n",
    "The above LDA model is built with 20 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
    "\n",
    "You can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics() as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.041*\"cd\" + 0.007*\"st\" + 0.002*\"targa\" + 0.002*\"remixe\" + 0.000*\"eq\" + '\n",
      "  '0.000*\"vamp\" + 0.000*\"duran\" + 0.000*\"transvision\" + 0.000*\"nitzer\" + '\n",
      "  '0.000*\"ebb\"'),\n",
      " (1,\n",
      "  '0.021*\"blue\" + 0.018*\"vote\" + 0.018*\"dream\" + 0.017*\"implement\" + '\n",
      "  '0.016*\"relationship\" + 0.015*\"gordon_bank\" + 0.013*\"seal\" + '\n",
      "  '0.013*\"homosexual\" + 0.013*\"pocket\" + 0.012*\"excuse\"'),\n",
      " (2,\n",
      "  '0.036*\"motorcycle\" + 0.019*\"bruin\" + 0.017*\"root\" + 0.014*\"brian\" + '\n",
      "  '0.011*\"ranger\" + 0.009*\"uunet\" + 0.008*\"maine\" + 0.006*\"phase\" + '\n",
      "  '0.005*\"boss\" + 0.005*\"inferior\"'),\n",
      " (3,\n",
      "  '0.020*\"line\" + 0.020*\"write\" + 0.014*\"get\" + 0.013*\"article\" + 0.013*\"know\" '\n",
      "  '+ 0.012*\"make\" + 0.012*\"say\" + 0.011*\"think\" + 0.011*\"go\" + 0.010*\"people\"'),\n",
      " (4,\n",
      "  '0.051*\"bike\" + 0.029*\"turkish\" + 0.024*\"logic\" + 0.023*\"turk\" + 0.017*\"pit\" '\n",
      "  '+ 0.016*\"street\" + 0.016*\"dog\" + 0.015*\"fair\" + 0.015*\"truck\" + '\n",
      "  '0.014*\"ensure\"'),\n",
      " (5,\n",
      "  '0.079*\"game\" + 0.077*\"team\" + 0.057*\"player\" + 0.042*\"play\" + 0.029*\"win\" + '\n",
      "  '0.027*\"run\" + 0.027*\"fan\" + 0.017*\"league\" + 0.017*\"year\" + 0.015*\"score\"'),\n",
      " (6,\n",
      "  '0.041*\"therefore\" + 0.019*\"blood\" + 0.018*\"die\" + 0.018*\"imply\" + '\n",
      "  '0.017*\"liar\" + 0.016*\"sake\" + 0.013*\"gather\" + 0.012*\"essential\" + '\n",
      "  '0.012*\"assert\" + 0.012*\"phrase\"'),\n",
      " (7,\n",
      "  '0.091*\"firearm\" + 0.028*\"uniform\" + 0.025*\"gun\" + 0.021*\"shotgun\" + '\n",
      "  '0.019*\"rifle\" + 0.017*\"os\" + 0.016*\"pistol\" + 0.013*\"handgun\" + '\n",
      "  '0.011*\"quit\" + 0.010*\"professor\"'),\n",
      " (8,\n",
      "  '0.048*\"medical\" + 0.023*\"guilty\" + 0.018*\"steve_hendrick\" + 0.015*\"thor\" + '\n",
      "  '0.013*\"cpu\" + 0.012*\"critical\" + 0.011*\"feasible\" + 0.009*\"spending\" + '\n",
      "  '0.008*\"photo\" + 0.007*\"middle_east\"'),\n",
      " (9,\n",
      "  '0.028*\"gif\" + 0.014*\"gary_dare\" + 0.013*\"tiff\" + 0.012*\"plot\" + '\n",
      "  '0.009*\"element\" + 0.009*\"au\" + 0.007*\"compact\" + 0.006*\"consultant\" + '\n",
      "  '0.006*\"winnipeg_jet\" + 0.006*\"souviens\"'),\n",
      " (10,\n",
      "  '0.045*\"argument\" + 0.035*\"christian\" + 0.028*\"sin\" + 0.023*\"food\" + '\n",
      "  '0.023*\"truth\" + 0.021*\"religion\" + 0.019*\"bible\" + 0.016*\"atheist\" + '\n",
      "  '0.016*\"human\" + 0.016*\"death\"'),\n",
      " (11,\n",
      "  '0.608*\"ax\" + 0.020*\"sale\" + 0.010*\"cap\" + 0.010*\"launch\" + 0.009*\"orbit\" + '\n",
      "  '0.008*\"reduce\" + 0.006*\"rocket\" + 0.005*\"ns\" + 0.005*\"shuttle\" + '\n",
      "  '0.004*\"distribution_usa\"'),\n",
      " (12,\n",
      "  '0.017*\"government\" + 0.017*\"law\" + 0.013*\"issue\" + 0.012*\"section\" + '\n",
      "  '0.012*\"state\" + 0.010*\"country\" + 0.010*\"public\" + 0.010*\"right\" + '\n",
      "  '0.008*\"protect\" + 0.008*\"police\"'),\n",
      " (13,\n",
      "  '0.033*\"drive\" + 0.023*\"system\" + 0.020*\"chip\" + 0.015*\"card\" + '\n",
      "  '0.014*\"memory\" + 0.013*\"driver\" + 0.013*\"use\" + 0.011*\"problem\" + '\n",
      "  '0.011*\"drug\" + 0.011*\"water\"'),\n",
      " (14,\n",
      "  '0.026*\"pro\" + 0.023*\"creation\" + 0.017*\"growth\" + 0.014*\"cell\" + '\n",
      "  '0.012*\"lawyer\" + 0.012*\"north\" + 0.007*\"depth\" + 0.007*\"spread\" + '\n",
      "  '0.006*\"programmer\" + 0.006*\"unarmed\"'),\n",
      " (15,\n",
      "  '0.009*\"contrast\" + 0.007*\"nec\" + 0.004*\"interleave\" + 0.000*\"sampling\" + '\n",
      "  '0.000*\"antenna\" + 0.000*\"heinbokel\" + 0.000*\"ak\" + 0.000*\"simulation\" + '\n",
      "  '0.000*\"shift\" + 0.000*\"bower\"'),\n",
      " (16,\n",
      "  '0.025*\"mouse\" + 0.024*\"mhz\" + 0.011*\"pre\" + 0.010*\"screw\" + 0.005*\"xavi\" + '\n",
      "  '0.004*\"hammer\" + 0.004*\"ep\" + 0.002*\"spill\" + 0.001*\"refill\" + '\n",
      "  '0.001*\"static\"'),\n",
      " (17,\n",
      "  '0.034*\"export\" + 0.016*\"nearly\" + 0.007*\"pentium\" + 0.004*\"sweden\" + '\n",
      "  '0.003*\"emerge\" + 0.002*\"lcs\" + 0.002*\"chalmer\" + 0.001*\"integer\" + '\n",
      "  '0.000*\"privacy\" + 0.000*\"key_escrow\"'),\n",
      " (18,\n",
      "  '0.029*\"car\" + 0.020*\"key\" + 0.013*\"mention\" + 0.012*\"block\" + 0.011*\"bit\" + '\n",
      "  '0.010*\"eat\" + 0.010*\"unit\" + 0.009*\"big\" + 0.009*\"chance\" + 0.009*\"season\"'),\n",
      " (19,\n",
      "  '0.014*\"program\" + 0.013*\"window\" + 0.013*\"do\" + 0.013*\"system\" + '\n",
      "  '0.013*\"file\" + 0.012*\"use\" + 0.012*\"technology\" + 0.011*\"line\" + '\n",
      "  '0.009*\"software\" + 0.009*\"computer\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "# doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to interpret this?\n",
    "\n",
    "Topic 0 is a represented as _0.016“car” + 0.014“power” + 0.010“light” + 0.009“drive” + 0.007“mount” + 0.007“controller” + 0.007“cool” + 0.007“engine” + 0.007“back” + ‘0.006“turn”.\n",
    "\n",
    "It means the top 10 keywords that contribute to this topic are: ‘car’, ‘power’, ‘light’.. and so on and the weight of ‘car’ on topic 0 is 0.016.\n",
    "\n",
    "The weights reflect how important a keyword is to that topic.\n",
    "\n",
    "Looking at these keywords, can you guess what this topic could be? You may summarise it either are ‘cars’ or ‘automobiles’.\n",
    "\n",
    "Likewise, can you go through the remaining topic keywords and judge what the topic is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Model Perplexity and Coherence Score\n",
    "\n",
    "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. In my experience, topic coherence score, in particular, has been more helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -12.159954067483701\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4812691560239295\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the topics-keywords\n",
    "\n",
    "Now that the LDA model is built, the next step is to examine the produced topics and the associated keywords. There is no better tool than pyLDAvis package’s interactive chart and is designed to work well with jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ndah/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/ndah/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el867112095051360608770336\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el867112095051360608770336_data = {\"mdsDat\": {\"x\": [0.39296306806649767, 0.3251524636579569, 0.23978817798391663, 0.00890259241987553, 0.1458058189397384, 0.15139702797239685, -0.029064589527757177, -0.04467266754777893, -0.09133063317402511, -0.09217019119553356, -0.09773313866049595, -0.10284856169562062, -0.1054122118624343, -0.1031053345756129, -0.10319676830484499, -0.10148434388728075, -0.09933320536109685, -0.09803807656681841, -0.0990256601584174, -0.09659376652266427], \"y\": [-0.06283370237084929, 0.15608402204529676, -0.2765735358858829, -0.04860531507374297, 0.24989218931449655, 0.02235351957761693, -0.029282208745047937, -0.02005868094905698, -0.008882644035374723, 0.013215213145267038, 0.0004661527055721579, -0.00013098278518863007, 0.0005199975570740924, 0.0002385794488405333, 0.0003418432107654987, 0.00032552383395213075, 0.0012245393569942904, 0.0006900662350689819, 0.00047964322091232834, 0.0005357801932849292], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [46.69760672102302, 16.884972712494697, 9.873119302436404, 7.211825700652123, 5.976937754633683, 5.956381933375035, 1.8648259888592897, 1.3954579245401453, 1.117042994992435, 0.928894535497264, 0.6615985910043163, 0.3827491154053097, 0.2800978558531056, 0.18892046251301015, 0.18249294617282247, 0.13662590410176395, 0.10216615566888217, 0.06577545444485486, 0.061317012708191426, 0.031190933623640445]}, \"tinfo\": {\"Term\": [\"ax\", \"year\", \"system\", \"run\", \"drive\", \"argument\", \"write\", \"say\", \"car\", \"game\", \"team\", \"problem\", \"use\", \"key\", \"line\", \"program\", \"government\", \"make\", \"believe\", \"law\", \"play\", \"people\", \"sale\", \"do\", \"file\", \"window\", \"player\", \"get\", \"technology\", \"article\", \"well\", \"thing\", \"m\", \"come\", \"much\", \"tell\", \"seem\", \"point\", \"make\", \"really\", \"hear\", \"little\", \"cause\", \"live\", \"true\", \"course\", \"opinion\", \"least\", \"talk\", \"wrong\", \"actually\", \"probably\", \"quite\", \"life\", \"different\", \"fire\", \"enough\", \"happen\", \"study\", \"far\", \"think\", \"go\", \"way\", \"write\", \"see\", \"know\", \"sure\", \"article\", \"time\", \"take\", \"even\", \"try\", \"let\", \"day\", \"s\", \"get\", \"give\", \"say\", \"want\", \"line\", \"look\", \"good\", \"people\", \"nntp_poste\", \"organization\", \"host\", \"also\", \"work\", \"program\", \"technology\", \"software\", \"computer\", \"encryption\", \"mail\", \"available\", \"access\", \"internet\", \"image\", \"user\", \"file\", \"code\", \"email\", \"phone\", \"service\", \"graphic\", \"design\", \"server\", \"info\", \"communication\", \"distribution\", \"review\", \"manufacturer\", \"display\", \"manual\", \"electronic\", \"video\", \"apple\", \"object\", \"window\", \"product\", \"research\", \"application\", \"do\", \"address\", \"information\", \"network\", \"send\", \"space\", \"list\", \"message\", \"system\", \"device\", \"use\", \"new\", \"datum\", \"include\", \"also\", \"line\", \"need\", \"run\", \"government\", \"law\", \"protect\", \"police\", \"act\", \"agency\", \"criminal\", \"weapon\", \"crime\", \"prevent\", \"commit\", \"society\", \"cop\", \"individual\", \"safety\", \"supply\", \"tax\", \"israeli\", \"fund\", \"federal\", \"president\", \"citizen\", \"property\", \"fee\", \"officer\", \"troop\", \"political\", \"separate\", \"grant\", \"demand\", \"private\", \"section\", \"country\", \"important\", \"public\", \"issue\", \"present\", \"approach\", \"state\", \"division\", \"member\", \"purpose\", \"policy\", \"statement\", \"right\", \"provide\", \"today\", \"carry\", \"license\", \"follow\", \"people\", \"group\", \"ax\", \"sale\", \"cap\", \"launch\", \"orbit\", \"reduce\", \"rocket\", \"ns\", \"shuttle\", \"distribution_usa\", \"hard_drive\", \"guide\", \"reflect\", \"battery\", \"kit\", \"client\", \"vga\", \"atf\", \"annual\", \"weeks_ago\", \"frame\", \"max\", \"layer\", \"procedure\", \"shop\", \"orbital\", \"copper\", \"dance\", \"core\", \"complaint\", \"drive\", \"card\", \"memory\", \"drug\", \"water\", \"increase\", \"valid\", \"meet\", \"error\", \"acquire\", \"motif\", \"scsi\", \"ide\", \"generally\", \"instal\", \"secure\", \"bus\", \"switch\", \"manufacture\", \"civilian\", \"pin\", \"bug\", \"proper\", \"chemistry\", \"dangerous\", \"respond\", \"ram\", \"safe\", \"channel\", \"space_station\", \"board\", \"driver\", \"chip\", \"speed\", \"define\", \"system\", \"control\", \"problem\", \"use\", \"device\", \"datum\", \"run\", \"mention\", \"block\", \"eat\", \"unit\", \"season\", \"pick\", \"knowledge\", \"owner\", \"kid\", \"stay\", \"performance\", \"goal\", \"choose\", \"appreciate\", \"chance\", \"auto\", \"miss\", \"economic\", \"paint\", \"unfortunately\", \"btw\", \"tank\", \"sit\", \"trade\", \"career\", \"hot\", \"apr\", \"stream\", \"encrypt\", \"listen\", \"shoot\", \"car\", \"family\", \"arm\", \"key\", \"replace\", \"front\", \"die\", \"big\", \"bit\", \"man\", \"start\", \"back\", \"woman\", \"need\", \"christian\", \"sin\", \"truth\", \"bible\", \"atheist\", \"faith\", \"animal\", \"scripture\", \"context\", \"interpretation\", \"construct\", \"gentile\", \"motherboard\", \"artificial\", \"sex\", \"morality\", \"seizure\", \"stone\", \"correctly\", \"seed\", \"probability\", \"worship\", \"grand\", \"derive\", \"mp\", \"middle\", \"food\", \"christianity\", \"attend\", \"survive\", \"marriage\", \"argue\", \"religion\", \"argument\", \"moral\", \"death\", \"human\", \"man\", \"woman\", \"exist\", \"believe\", \"child\", \"say\", \"game\", \"team\", \"player\", \"fan\", \"league\", \"score\", \"originator\", \"tor\", \"det\", \"playoff\", \"rbi\", \"leafs\", \"hitter\", \"slg\", \"out\", \"scoring\", \"wrist\", \"flip\", \"rough\", \"runs_score\", \"leaf\", \"obp\", \"annoy\", \"clark\", \"gord\", \"niguma\", \"bench\", \"last_year\", \"jay\", \"dependant\", \"win\", \"play\", \"prediction\", \"wing\", \"statistic\", \"run\", \"hit\", \"average\", \"pretty\", \"year\", \"early\", \"defense\", \"injury\", \"major\", \"list\", \"lose\", \"next\", \"first\", \"bike\", \"turkish\", \"logic\", \"turk\", \"dog\", \"fair\", \"truck\", \"ensure\", \"reverse\", \"revelation\", \"repeat\", \"hawk\", \"popular\", \"lucky\", \"survivor\", \"microwave\", \"destruction\", \"koresh\", \"mask\", \"electric\", \"tough\", \"grab\", \"grade\", \"nail\", \"tail\", \"roof\", \"cage\", \"scene\", \"biker\", \"luck\", \"pit\", \"street\", \"city\", \"village\", \"burn\", \"blue\", \"vote\", \"dream\", \"implement\", \"relationship\", \"gordon_bank\", \"seal\", \"homosexual\", \"pocket\", \"excuse\", \"gay\", \"perfect\", \"title\", \"ai\", \"franchise\", \"surrender\", \"tree\", \"literature\", \"intellect\", \"engage\", \"shameful\", \"chastity\", \"jxp_skepticism\", \"everywhere\", \"contrary\", \"processor\", \"permanent\", \"educate\", \"yeast\", \"bull\", \"computer_science\", \"teach\", \"degree\", \"associate\", \"imply\", \"liar\", \"gather\", \"essential\", \"assert\", \"phrase\", \"rise\", \"equal\", \"forever\", \"constitution\", \"affair\", \"possession\", \"heal\", \"crazy\", \"militia\", \"be\", \"blind\", \"import\", \"bird\", \"lunatic\", \"sentence\", \"sake\", \"stretch\", \"obligation\", \"second_amendment\", \"paraphrase\", \"pilot\", \"ninth\", \"adjective\", \"doubtful\", \"therefore\", \"blood\", \"applicable\", \"die\", \"fool\", \"define\", \"firearm\", \"uniform\", \"shotgun\", \"rifle\", \"os\", \"pistol\", \"handgun\", \"quit\", \"professor\", \"ray_trace\", \"inflict\", \"physically\", \"fatal\", \"okay\", \"univ\", \"lethal\", \"roughly\", \"david_veal\", \"gunshot\", \"elevator\", \"unite\", \"mainstream\", \"cont\", \"tenn\", \"holster\", \"thigh\", \"closing\", \"tote\", \"holstered\", \"assimilation\", \"gun\", \"wear\", \"accident\", \"wound\", \"shoot\", \"division\", \"medical\", \"guilty\", \"steve_hendrick\", \"thor\", \"critical\", \"feasible\", \"spending\", \"photo\", \"middle_east\", \"purdue_university\", \"govt\", \"substantial\", \"exe\", \"analyze\", \"config\", \"dissemination\", \"turbo\", \"idle\", \"query\", \"waterloo\", \"suspicious\", \"ext\", \"coffee\", \"extract\", \"informative\", \"geezer\", \"regulator\", \"temperature\", \"interpreter\", \"cpu\", \"pro\", \"creation\", \"growth\", \"cell\", \"lawyer\", \"north\", \"depth\", \"programmer\", \"unarmed\", \"holly\", \"lady\", \"carnegie_mellon\", \"comp_graphic\", \"arkansa\", \"speedstar\", \"frontier\", \"specialized\", \"endometriosis\", \"continent\", \"spread\", \"hal\", \"distinguished\", \"genesis\", \"rink\", \"ice\", \"contradiction\", \"cancer\", \"hockey\", \"headquarter\", \"brian_kendig\", \"chapter\", \"bath\", \"specifically\", \"privacy\", \"edge\", \"truly\", \"motorcycle\", \"bruin\", \"root\", \"brian\", \"ranger\", \"uunet\", \"maine\", \"phase\", \"boss\", \"inferior\", \"shade\", \"tournament\", \"semi\", \"closed\", \"walsh\", \"bbbllluueeee\", \"fanatical\", \"ggggooooooo\", \"umaine\", \"stress\", \"rainbow\", \"assistant\", \"globe\", \"wwii\", \"neely\", \"wesley\", \"defenseman\", \"canadien\", \"decent\", \"draft\", \"gif\", \"gary_dare\", \"tiff\", \"plot\", \"au\", \"compact\", \"consultant\", \"souviens\", \"winnipeg_jet\", \"je\", \"baldrick\", \"gld\", \"builder\", \"rap\", \"phds\", \"magnus\", \"element\", \"rely\", \"ozone\", \"devil\", \"chlorine\", \"monoxide\", \"upper\", \"limb\", \"sounder\", \"atmosphere\", \"satellite\", \"jet_propulsion\", \"exponent_graphic\", \"poll\", \"western\", \"pre\", \"screw\", \"xavi\", \"hammer\", \"ep\", \"mouse\", \"spill\", \"mhz\", \"refill\", \"static\", \"warrantee\", \"fpu\", \"comparision\", \"deluxe\", \"eufrat\", \"fischer\", \"iisi\", \"blaze\", \"tab\", \"scare\", \"carol\", \"cheer\", \"ink\", \"beep\", \"freeze\", \"lh\", \"chensun\", \"pfaffenwaldring\", \"stuttgart\", \"amigas\", \"audio\", \"commodore\", \"revolver\", \"cartridge\", \"dx\", \"compare\", \"baseball\", \"cd\", \"st\", \"targa\", \"remixe\", \"eq\", \"vamp\", \"duran\", \"ebb\", \"nitzer\", \"transvision\", \"bezel\", \"ballad\", \"cannibal\", \"civille\", \"comin\", \"hobb\", \"moby\", \"morissey\", \"motown\", \"nmt\", \"remix\", \"tranvision\", \"vanessa\", \"velveteen\", \"william\", \"sister\", \"dwarf\", \"swing\", \"rocker\", \"pinzone\", \"mixed\", \"dealer\", \"jack\", \"underground\", \"weather\", \"alive\", \"boy\", \"cs\", \"raw\", \"ant\", \"healer\", \"export\", \"nearly\", \"pentium\", \"sweden\", \"emerge\", \"lcs\", \"chalmer\", \"integer\", \"pkware\", \"pkzip\", \"bonne\", \"uwe\", \"permission\", \"sunrise\", \"dell\", \"schlafly\", \"aladin\", \"referring\", \"astronomical\", \"exportability\", \"sunset_time\", \"elwood\", \"clae\", \"hacket\", \"sunkbd\", \"sparc\", \"strength\", \"appelquist\", \"tick\", \"umpire\", \"prior\", \"key_escrow\", \"scheme\", \"microcircuit\", \"privacy\", \"genocide\", \"initiative\", \"armenian\", \"decision\", \"conclusion\", \"legal\", \"attempt\", \"propose\", \"management\", \"contrast\", \"nec\", \"interleave\", \"sampling\", \"heinbokel\", \"hansch\", \"matthias\", \"theoretische\", \"ak\", \"adress\", \"universitaet\", \"elbow\", \"antenna\", \"flasher\", \"derivative\", \"flux\", \"hf\", \"improved\", \"loran\", \"mininec\", \"uhf\", \"vhf\", \"lciii\", \"mesh\", \"evidentally\", \"fernando\", \"adoption\", \"deviate\", \"fxwg\", \"glide\", \"fortran\", \"simulation\", \"arrange\", \"sincerely\", \"bower\", \"albion\", \"convertor\", \"multiplication\", \"shift\", \"few\", \"mode\", \"shirt\", \"clutch\", \"ice\", \"wisdom\", \"transmission\", \"hockey\", \"monitor\"], \"Freq\": [5588.0, 406.0, 461.0, 286.0, 252.0, 187.0, 1229.0, 780.0, 250.0, 140.0, 137.0, 357.0, 579.0, 260.0, 1457.0, 293.0, 220.0, 725.0, 220.0, 213.0, 122.0, 678.0, 183.0, 330.0, 271.0, 279.0, 102.0, 925.0, 248.0, 794.0, 549.2769403818501, 416.2256185432601, 408.2343900913001, 349.3261409882875, 360.5717845116077, 322.91203952786793, 289.24915676688875, 257.66984623098745, 723.7427303182452, 235.8923301430559, 197.14341676900764, 195.60291727631636, 181.33712154398256, 180.58704774558967, 178.50886963993005, 161.81985242536692, 153.42065382583397, 150.01635434112563, 149.8676208581418, 146.4599795153877, 144.88364864846272, 143.19395807396808, 142.51571342361328, 141.52537251169616, 139.18838760700518, 135.96065193348772, 135.68596784208114, 176.57221436918869, 133.49045030578483, 128.0289390613307, 656.4254511743949, 651.678570619765, 362.5887414418642, 1205.283009171445, 538.0143518355758, 745.632094650979, 209.51457312221308, 775.4345905704699, 506.3051387014466, 449.8395798304404, 362.266425473332, 325.23492206893826, 221.93960133644705, 305.42413797416015, 326.5871404473321, 847.8499642962684, 383.3577374647748, 703.0927654549406, 402.405468594642, 1205.6121475223779, 375.3056622364459, 467.5439672256868, 587.8583448546822, 535.7428867618654, 557.0550664502099, 514.5892303979169, 371.6804257216815, 343.14484066731603, 293.0129089585291, 247.79867517819193, 203.87526297899757, 201.50340188903337, 191.34682090767242, 179.83351548764972, 162.0705293763653, 146.8178585172125, 144.11504916086085, 135.18099025325358, 132.13606163488515, 270.4013697980979, 113.18947143372276, 102.25960485365259, 95.32115306203372, 93.05942756003829, 90.79256781229579, 141.40281365020795, 86.1812530168288, 81.21188976135826, 74.57773729457836, 72.88121503509204, 70.75235819744935, 68.36933112576767, 65.21999280677728, 63.01049221074028, 62.808326270537755, 59.02726012644836, 57.52254005134507, 57.092040564930315, 275.99426814668436, 121.29741816723889, 124.90871826958038, 135.09085014579193, 274.5000823004039, 109.6396418908139, 184.066059325386, 98.7485228216161, 183.48173803694567, 123.90350916376545, 142.43274134150434, 140.1514314997745, 271.39117616667164, 151.17479750825413, 254.5734728866231, 186.80036607605703, 134.30762697377148, 141.65352929897378, 183.3609829836524, 237.65398719576854, 148.45145116891422, 131.18844232072138, 219.68783887309897, 212.45521897897058, 102.75454609529682, 100.34798055278053, 84.31554255905858, 81.39667269516269, 81.02155201484244, 80.22928658361413, 78.51613286467443, 70.67939716636137, 69.46339635281149, 68.49286137810874, 65.44513997923767, 76.25009318733291, 55.85765347246223, 54.57951074457027, 52.72828798835819, 52.666234027282314, 50.92353973800336, 50.17143376811954, 48.53570824118655, 45.77397861444959, 43.483646244985096, 41.47436560587012, 40.35270346564063, 40.311731902471614, 39.89128304053017, 38.59328632868254, 38.156733223700854, 37.642142117400184, 71.28023524549253, 156.1530496991605, 130.02136032398283, 65.09743140021476, 126.571387593946, 163.468427753227, 67.08597852271211, 66.25009999855341, 150.7413204115092, 89.34414155561484, 65.15162820284391, 68.01397929788311, 82.21445043713852, 67.91401161552625, 122.71841299820521, 92.0255141465808, 87.5967505619211, 74.74540043637673, 77.18060942591707, 79.64175876543376, 89.39154250254268, 73.56383039476651, 5587.992721360674, 182.89181677153206, 93.73021331991337, 92.17793890583934, 81.75264800746213, 76.59303937170056, 52.032587512715665, 49.416544441834304, 48.949972103089756, 38.79552316012495, 36.44358054870718, 34.75628562063166, 33.24874964107689, 32.150592502075774, 31.271084262812202, 31.19497902678015, 30.709443553783142, 29.48438867528303, 28.794438966961362, 28.785669454283347, 27.25542911003693, 26.168577040004617, 25.027857247895923, 24.834347617835355, 24.02781371654883, 23.28050989625096, 22.934554227241154, 22.909813279751752, 22.445303222010605, 22.07869904476114, 252.02081516276985, 113.94134803071076, 106.70387512525724, 84.73884229167945, 84.66167298459035, 74.797646516949, 71.41176685102283, 63.13070507962724, 61.90538852988879, 61.77975235440068, 60.63914456015322, 58.69327824111256, 57.367364719759344, 50.926673784116105, 48.61995753774961, 46.93289946844093, 44.84382267587176, 43.78954227575525, 42.101426411896774, 38.59004190738968, 38.46928649534442, 35.41255841671162, 35.324431351987556, 35.018955904449676, 34.42916090036982, 33.850930643414905, 33.10346035778502, 32.40995889207153, 30.548304378062227, 30.2306997896631, 55.31807946042241, 99.36202132540345, 151.63413878393644, 83.20672982603894, 50.10655999022594, 175.85776176151117, 75.66471857962857, 87.12294082390345, 96.23860249508758, 57.63332905611007, 53.843045304717165, 57.76726075462795, 97.16353762996687, 87.80976562612598, 78.25300126662495, 78.0421204237014, 67.07006947575482, 64.1180489693899, 62.89715876169417, 58.3996067285202, 56.13800926705153, 55.13966637357739, 53.91645206896146, 53.09706463834267, 52.73762553931458, 50.88357633686596, 68.99989768006722, 46.81452127193794, 46.227501084080274, 44.312661005568295, 42.10750337113431, 39.77864859650924, 39.48707878745215, 38.478120041835666, 37.72724925238482, 38.48417259865524, 36.88390629004063, 35.92656938058316, 35.31348181037397, 33.21862503753623, 33.075118243230825, 31.57738104441083, 63.80965510408856, 223.0650395318667, 42.29210458541224, 56.17608271477163, 152.5456847822184, 44.73099491376595, 66.11786185173766, 55.44205366875621, 70.81677548154559, 81.37066585576804, 57.36320453707889, 64.78992876305985, 59.915706769216534, 46.527695167553574, 54.12523521101183, 83.08960775155094, 65.53026050712504, 54.204857708705156, 44.31067571627056, 38.46166806336606, 35.08552036463995, 35.03854011662409, 32.259936429566295, 21.35471114777137, 18.4716445202704, 17.219772638464445, 16.802863361158078, 15.428197160663819, 15.11264538732169, 13.62468834546643, 14.186280617127892, 13.025944908795731, 12.834012543363304, 12.556515656915865, 12.256070215090384, 12.03231155575811, 11.85885343636888, 11.021532959450015, 10.528176120149535, 10.374589914719488, 9.72909437550892, 54.57489638072442, 29.439839060939377, 9.393070421955262, 9.251361071304139, 26.626473091356317, 33.64709193361724, 49.182884051258625, 106.33835827589547, 33.18226435383794, 37.15392711999934, 37.16755604343364, 31.865065340738653, 22.42318729195504, 18.640260639557663, 17.11907852838426, 15.596469954234797, 14.314511664658953, 139.84138751062613, 136.29050919035654, 101.92603623670995, 47.34237569813163, 31.05711758641592, 26.149883612697455, 23.873904853500246, 19.574826865579716, 19.343965541420534, 17.051506277451644, 14.603484175823912, 11.378948193253231, 9.010048426512476, 7.246685798386792, 6.144681533828487, 5.962516264161264, 5.08673357187819, 4.733152737230133, 4.717529987785747, 4.333961695395628, 3.2428492659958206, 3.2172852566203898, 3.167762317705421, 3.0498412645547788, 2.995877473541898, 2.995877473541898, 2.3231120000578076, 2.2701437439115155, 1.9337068276965022, 1.6355375051602425, 52.1062244735916, 75.32501973180258, 10.058888435760329, 14.057769462857006, 11.060957160320719, 48.4839477601263, 18.990741068889136, 11.255003791581991, 15.161278735796353, 29.436816944396416, 13.387787136066546, 7.901094271930268, 7.172097549872434, 7.965401887753649, 8.92127282200966, 7.368667722169097, 7.3054200764554915, 7.3503830305882, 72.95745080284655, 41.902985067181326, 33.86905124152414, 32.13623418029048, 23.061538061641254, 21.928972991270925, 21.080053041663522, 19.90059214428627, 19.08878683518996, 17.423802541129273, 17.109146070397955, 15.677705515756069, 14.140890323092131, 12.494449417862924, 13.133107027867352, 12.29662319614185, 11.121261454445401, 10.759040448352055, 10.448062536975009, 9.957448199897579, 9.240404437290474, 8.84250837117274, 8.412729909381989, 8.343785281888414, 8.256650858374147, 7.894350244143286, 7.380039218132669, 7.645121711430885, 7.094516672126713, 7.022534994186997, 23.702256195604992, 23.24559738278166, 17.180504151260482, 10.802914483139189, 9.096108717436923, 25.001040042923716, 20.915639627619328, 20.78483846125365, 20.38771053241795, 18.835824732442884, 18.32276953665928, 15.785847859435288, 15.185398436748505, 15.118785301421156, 14.807259802689103, 14.739096498332605, 13.429102162970915, 11.684456981682882, 10.225286736175113, 9.787430736490986, 9.496482214551566, 8.721540028663277, 8.64248747645397, 8.610345466377675, 8.275239745232106, 8.241299318417367, 8.185031492628681, 8.185031492628681, 7.7643294096568045, 7.29666658334848, 7.261690687755194, 7.197224067620878, 5.799622012326019, 5.7565102118067895, 5.661632695622324, 10.482004657310707, 8.659599466886426, 9.356592975379403, 8.153612159217221, 15.129587781228988, 14.176858180558584, 11.369624436175076, 10.092010568289146, 9.858939233400385, 9.826544792442569, 9.800232707766769, 9.658803779195319, 9.251593955285163, 8.595641691967392, 8.442468472099469, 7.785630573700323, 7.470834845237832, 7.392924104769607, 6.674942023219171, 6.3785764629585, 6.333578813983766, 5.606504238459034, 5.337472740179688, 5.065816948773238, 4.5433107178653085, 13.425618026325019, 4.2066295084655945, 3.9813288945193017, 3.5640505706268057, 3.5387416032370504, 3.2714023987888825, 2.9330758491481514, 2.8768052129053854, 2.70901272752164, 34.30376960648582, 16.448401361667045, 6.209714064386388, 15.309003146533811, 7.337843417880851, 5.093732135104763, 44.353060506292856, 13.603355371437054, 10.359864183559306, 9.205300508034819, 8.485460098681221, 7.891255408822782, 6.311530078595472, 5.522698950968553, 4.700138047778206, 2.7457157042799456, 2.721557769181254, 2.686407754257507, 2.418636943633263, 2.326897846002823, 2.168648448136803, 1.7987947511351092, 1.3334222285766972, 1.0962479381793513, 0.9349856461709902, 0.7684429187688694, 0.6624818219582821, 0.6560184599270223, 0.5592120310001816, 0.5592120310001816, 0.5343347132965655, 0.5343347132965655, 0.5077018724527855, 0.46350550335450985, 0.3901430255585689, 0.31444208546760843, 12.371398652460817, 2.311215884858609, 1.0166775959579442, 0.758000249720685, 0.8515437423642832, 0.8959645811117771, 16.97284946078404, 8.129779819118884, 6.344717456276003, 5.2682788703887695, 4.33205021359796, 3.7860859503636473, 3.0810153546492054, 2.8622205677399197, 2.659728328638772, 2.5186207887756096, 2.3989524392087485, 2.3461520994254643, 2.3185028266339995, 2.235072933388959, 2.146117477349484, 1.9954509484018355, 1.8740953367877113, 1.7170673491777888, 1.6670969119823034, 1.4198645317805199, 1.3023475536084392, 0.9886057255222092, 0.9436059160733742, 0.923960200662468, 0.8871844421211211, 0.8839886583469913, 0.6642737621801954, 0.6638904145130439, 0.5375327354867924, 4.654714335955909, 6.2133967865193025, 5.5800454982599295, 3.978301129205962, 3.350278799764072, 2.9953032275996816, 2.8863144858220893, 1.7131878920756165, 1.476697056266816, 1.3364650831200422, 1.2809366949569085, 1.2422333027166366, 1.1902866130613887, 0.8889435624267641, 0.7830891294129796, 0.6425530434382879, 0.5598238076274469, 0.4565735195183596, 0.42045749857357134, 0.3852100869206236, 1.6276254309814022, 0.2796932298046432, 0.19322924331421987, 0.013678635510168022, 0.013678637263262631, 0.013679044857759096, 0.013678635510168022, 0.013679062388705181, 0.01367920088317925, 0.013678314693854676, 0.013678298039455894, 0.01367843390428805, 0.013678512793545431, 0.01367854171960647, 0.013678702127763143, 0.013696509186248526, 0.013679726811561786, 8.434477640808607, 4.374719612044946, 3.908907541830284, 3.253409104187522, 2.598300403953668, 2.134081531712015, 1.9279323353244495, 1.3035747403475908, 1.267445887456395, 1.1206394138540994, 1.066977037937087, 1.0666350964673699, 0.9290412088583886, 0.9278523797042432, 0.6405141397545744, 0.5747226501263104, 0.5747226501263104, 0.5747226501263104, 0.5747226501263104, 0.39515569096636666, 0.37658870268397676, 0.341365479878663, 0.25580852692137396, 0.24603162912221138, 0.01316595486085153, 0.01316595486085153, 0.013165993810206738, 0.013165971795353794, 0.01316595486085153, 0.01316611065827236, 4.944513998008566, 2.525689525316227, 2.3433183984971224, 2.009090285099963, 1.4919655769521738, 1.1350680175109755, 1.0474276586820583, 0.9722547486818451, 0.9722547486818451, 0.5846191814852248, 0.4976901436293951, 0.4753943104776831, 0.40959653219616987, 0.3819530323528133, 0.9077911282854617, 0.2919831409502239, 1.521217166079182, 0.35876416336812345, 0.010273337743117344, 0.010272225860358052, 0.010271751059795504, 0.010271552645141194, 0.010271552645141194, 0.010271552645141194, 0.010271554546879095, 0.010271552645141194, 0.010271669918978406, 0.010271354230486885, 0.010271207796668529, 0.010271183707988452, 0.07196904962320529, 1.4469771210275406, 1.258475810104758, 0.6294757530211695, 0.576036289825111, 0.4599608989091037, 3.314627692586668, 0.2530893819141303, 3.106882296670647, 0.1507176593617191, 0.1333822133047718, 0.13244588412304117, 0.008062767413912098, 0.008062497218316174, 0.008062497218316174, 0.008062497218316174, 0.008062497218316174, 0.008062474465002833, 0.008062497218316174, 0.00806248110138589, 0.008062497218316174, 0.008062461192236718, 0.008062550309380636, 0.008062404308953365, 0.008062477309167001, 0.008062477309167001, 0.008062477309167001, 0.008062376815366411, 0.008062376815366411, 0.008062376815366411, 0.00806238724396836, 0.008062409049226978, 0.00806238724396836, 0.008062433698649764, 0.008062463088346163, 0.008062415685610036, 0.008062497218316174, 0.008062488685823672, 3.4329949244608846, 0.5824194327897321, 0.16581420748937714, 0.14656471461585283, 0.028455462432667136, 0.0053939139099294904, 0.005393758266643313, 0.005393758266643313, 0.005393758266643313, 0.005393758266643313, 0.005393755214814172, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393616051405354, 0.005393605675186276, 0.00539362398616112, 0.005393606895917932, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 0.005393602623357135, 2.663051201748114, 1.2245370429139522, 0.5597047699745019, 0.34045540535162105, 0.26046736653669644, 0.14126388267074888, 0.11837206138870596, 0.11026290189123746, 0.004937001117744885, 0.004937001117744885, 0.004936989168880362, 0.004936989168880362, 0.004937001117744885, 0.004936990306867459, 0.004936953891280343, 0.004936917475693227, 0.004936911216764191, 0.004936917475693227, 0.004936911216764191, 0.004936944787383564, 0.004936911216764191, 0.004936911216764191, 0.004936884474067403, 0.004936884474067403, 0.004936884474067403, 0.004936884474067403, 0.0049369197516674216, 0.004936867973254491, 0.004936867973254491, 0.004936874232183527, 0.004936937390467432, 0.004937084190802993, 0.004936921458648068, 0.004936944787383564, 0.0049371160544417194, 0.004936972099073901, 0.004936916906699678, 0.004937056310119107, 0.0049369493393319535, 0.004937003962712628, 0.004936949908325503, 0.004936932269525493, 0.004936923165628714, 0.004936918044686776, 0.34349029147855703, 0.28414505484959934, 0.16620046885564066, 0.0026435266186749374, 0.0026435130151146267, 0.002643499411554316, 0.002643499411554316, 0.002643499411554316, 0.0026435109890524527, 0.002643499411554316, 0.002643499411554316, 0.0026434979643670488, 0.002643523724300403, 0.002643497096054689, 0.002643498543241956, 0.002643498543241956, 0.002643498543241956, 0.002643498543241956, 0.002643498543241956, 0.002643498543241956, 0.002643498543241956, 0.002643498543241956, 0.0026434927544928873, 0.002643498543241956, 0.0026434921756179806, 0.0026434921756179806, 0.0026434915967430738, 0.0026434915967430738, 0.0026434915967430738, 0.0026434915967430738, 0.002643498543241956, 0.0026435109890524527, 0.002643499411554316, 0.002643499411554316, 0.002643508673552825, 0.0026435011481790367, 0.0026435011481790367, 0.0026435011481790367, 0.002643508673552825, 0.0026435011481790367, 0.0026435052003033845, 0.002643499411554316, 0.0026435011481790367, 0.0026435023059288502, 0.002643499411554316, 0.0026435011481790367, 0.0026435023059288502, 0.002643508384115372], \"Total\": [5588.0, 406.0, 461.0, 286.0, 252.0, 187.0, 1229.0, 780.0, 250.0, 140.0, 137.0, 357.0, 579.0, 260.0, 1457.0, 293.0, 220.0, 725.0, 220.0, 213.0, 122.0, 678.0, 183.0, 330.0, 271.0, 279.0, 102.0, 925.0, 248.0, 794.0, 549.9826813442487, 416.9254430415699, 409.056024426866, 350.0428642248631, 361.32747964690634, 323.61208341479835, 289.94899693193776, 258.3724495741447, 725.7162190811323, 236.59213717769822, 197.84322376723537, 196.30273656003718, 182.03693789008219, 181.2868547524527, 179.22689636317364, 162.51965942413796, 154.1204627062231, 150.71616944067313, 150.56753840308258, 147.15980139153262, 145.5834572792772, 143.89376887459116, 143.21552120825143, 142.2251795813803, 139.88936851973057, 136.66045894785273, 136.38577484865849, 177.48453617696737, 134.19025844049852, 128.7295627397009, 660.37343681056, 659.4049877511183, 365.0417988312844, 1229.701663621342, 545.2600815919034, 759.8683073695885, 211.06340740028332, 794.239954808502, 520.0810757244944, 461.0568470642613, 370.7105293149349, 333.76893491515966, 225.36740856076656, 314.2017609072327, 337.97449704787766, 925.9191032247287, 405.6597204875817, 780.5418580099945, 431.7187316268448, 1457.6440876726945, 403.6689537291596, 516.1581945474447, 678.4549481721165, 623.1334014744082, 673.8028002822937, 636.2204003525027, 595.380755810834, 427.89249794400115, 293.70879737586256, 248.4939716391495, 204.5705598836609, 202.1987119588225, 192.04211736863, 180.52881304286726, 162.7658259356538, 147.5131550960294, 144.810345647857, 135.88305243181736, 132.83135874060267, 271.8501633045773, 113.888090292892, 102.95490184162406, 96.01644993338618, 93.75474165605401, 91.48786427325328, 142.53870207753778, 86.8765495000174, 81.90718673100466, 75.27303375553585, 73.57658446932513, 71.44766600953153, 69.06881579355817, 65.91529371260006, 63.706009371848, 63.50362273149528, 59.7260595265812, 58.2178365192355, 57.78753701981822, 279.5159980784287, 124.18496012613461, 128.36956867523062, 142.31990594389887, 330.8223149196394, 118.62559670879983, 217.66745016755291, 106.59169294033002, 240.09900586283777, 145.32158864450733, 177.82182170357908, 176.4061801357683, 461.6348185384329, 209.4339917324675, 579.1494015395261, 340.45565928219895, 188.77653789076484, 239.29885993307184, 595.380755810834, 1457.6440876726945, 378.07388190907926, 286.7857555551319, 220.39130208232652, 213.15875454420615, 103.45800907431655, 101.05144353180026, 85.01970318527626, 82.10033900088126, 81.7250150560437, 80.93297585986272, 79.21959586449287, 71.38290285347533, 70.16686212463428, 69.20190505015033, 66.14874628965848, 77.08063356023409, 56.56113236462107, 55.282973730522926, 53.43175097227434, 53.36969722050674, 51.62700272191951, 50.87489674713929, 49.239171225102695, 46.477441605298644, 44.18711915556714, 42.181971469203184, 41.05616644466038, 41.01519654174431, 40.60520199413949, 39.296792282567026, 38.86019626615544, 38.34560509641993, 73.24468118564884, 163.10783732838902, 135.79454894999432, 67.29436572398878, 144.53516820366062, 200.39825648084965, 76.05196002667125, 75.70974139520438, 230.11648496217848, 119.76436356134296, 76.28919355806455, 83.84396598714669, 118.65604174445501, 84.55716937938826, 298.4890532923445, 174.63034629140293, 164.2959726778585, 108.88315947526634, 130.06849699574875, 239.6727139044452, 678.4549481721165, 227.42247603230436, 5588.648486715733, 183.54758217541624, 94.38597874783382, 92.83370428522493, 82.40841337418868, 77.24880490055713, 52.68835291154933, 50.07230990429865, 49.605737492902065, 39.451288574909306, 37.099345979129474, 35.41205101744847, 33.904515094675084, 32.80635797260545, 31.92684966675319, 31.85074441512882, 31.365208951101216, 30.14015406013787, 29.450204446668014, 29.441434953049455, 27.91119450257141, 26.82434241366409, 25.68362264175062, 25.49011308603135, 24.683579111263615, 23.936275263611442, 23.59031958230051, 23.565578821566774, 23.101068661684728, 22.73446442979382, 252.7211419974357, 114.64167488941162, 107.40420585138263, 85.43916911693525, 85.36366989356175, 75.49797335221291, 72.11562680848063, 63.83103191082415, 62.60571535374466, 62.480079198676286, 61.33947138457931, 59.39360506064225, 58.06769153928904, 51.62700062046891, 49.32028435727931, 47.63322629859315, 45.54414949540146, 44.48986914268066, 42.80190020641996, 39.290368739416316, 39.16961331487412, 36.11288523624132, 36.024758183915644, 35.71928273506005, 35.1294877384985, 34.55125749261991, 33.80378717731471, 33.11028571160123, 31.24863119759192, 30.931026636378927, 57.12336490524676, 109.20268688323527, 173.78959463905224, 98.32507987486676, 55.86792058229566, 461.6348185384329, 135.66276752387287, 357.5753233990542, 579.1494015395261, 209.4339917324675, 188.77653789076484, 286.7857555551319, 97.87060356689379, 88.51682634273932, 78.9600808102028, 78.7491811482808, 67.77713019560545, 64.82511633365303, 63.604219478307535, 59.10668081072408, 56.845371061534046, 55.84673560873683, 54.623512809836456, 53.80412536416229, 53.44468625592794, 51.59063706514653, 69.96292970117331, 47.52158200965846, 46.9345842248201, 45.0197217503596, 42.81456409293049, 40.48570931989342, 40.19413951083632, 39.18518076363185, 38.43431156522403, 39.209760351050846, 37.590967009891294, 36.63363009719652, 36.020542526987334, 33.92568575414959, 33.78217897046671, 32.28444177471638, 65.34571374561938, 250.38341549286218, 44.743577416750696, 63.11761618206634, 260.1235497741181, 50.19997522954087, 101.42091440495855, 76.66414875268207, 121.45608389962656, 194.05486101503476, 125.89633185841532, 232.72113162387558, 175.34795595911257, 71.87853574951082, 378.07388190907926, 83.8087437493245, 66.24938791294154, 54.92398511452168, 45.030417502217695, 39.1807954759534, 35.80464881316212, 35.75766752244061, 32.97906383538282, 22.073838556825198, 19.190771932857743, 17.938900044280974, 17.521991097699892, 16.147324578309647, 15.83177280994501, 14.343815751282953, 14.93929496104824, 13.745072341057933, 13.553139974639217, 13.275643109344557, 12.975197634610625, 12.75143900162908, 12.577980842185404, 11.740660376933752, 11.247303538463, 11.093717477855396, 10.448221799005205, 58.71965219973051, 31.684124225065418, 10.112197845259121, 9.970488493970697, 29.243315935757813, 39.68647580881191, 70.2001581930545, 187.1880373662289, 46.52475868828231, 78.10287584878813, 79.49668363098897, 125.89633185841532, 71.87853574951082, 90.80146745163748, 220.67051201174888, 123.52572389454433, 780.5418580099945, 140.5646980763796, 137.01381974920096, 102.6493467955543, 48.065686340629014, 31.78042819106928, 26.873194171541822, 24.59721542401183, 20.298137429606907, 20.067276105447725, 17.77481683629601, 15.326794734668276, 12.102258752097596, 9.733358995979364, 7.969996357231159, 6.867992179536692, 6.685826823005632, 5.810044130722558, 5.456463305914982, 5.440840566036114, 5.0572722542399955, 3.9661598248401875, 3.9405958154647567, 3.8910728914487533, 3.7731518233991457, 3.7191880323862647, 3.7191880323862647, 3.0464225589021745, 2.9934543027558824, 2.6570173865408693, 2.3588480640046097, 83.65589353674422, 122.89779931026561, 17.160869312875306, 26.486262233273962, 21.473910804453684, 286.7857555551319, 101.64632568776565, 41.61327139813148, 86.95462049863613, 406.57556912356154, 96.1636207104633, 33.01151219765263, 24.94928656268717, 80.04631737456711, 177.82182170357908, 85.33017122051136, 95.98286270802281, 301.28970702170074, 73.68307292223498, 42.62860718656979, 34.59467338773829, 32.86185629967894, 23.78716018102972, 22.65459511065939, 21.805675161051987, 20.62621438420041, 19.81440896134924, 18.149424664843917, 17.83476820358295, 16.403327638381835, 14.866512464200111, 13.22007156055244, 13.896012189417275, 13.022245321694534, 11.846883584930858, 11.484662601168475, 11.173684668030683, 10.683070319286038, 9.966026568723986, 9.56813051609422, 9.138352030546317, 9.06940740867272, 8.982272989429822, 8.619972363531748, 8.10566135001807, 8.415876455746956, 7.820138791515177, 7.748157123583578, 30.663048074438002, 30.134368816378444, 47.07245554240078, 24.027159021246234, 37.772283473353646, 25.734021910209552, 21.645294204763918, 21.51449302136441, 21.117365116854952, 19.565479317058145, 19.05242409677004, 16.51550242527217, 15.915053004255107, 15.848439861531912, 15.536914372852163, 15.468751058443361, 14.158906365723292, 12.414116534817538, 10.95494132061211, 10.517085303076344, 10.226136774662322, 9.451194616062663, 9.372142056884302, 9.34000002648843, 9.004894353070354, 8.970953878528123, 8.914686052739437, 8.914686052739437, 8.493984009234982, 8.026321173598879, 7.991345252762352, 7.926878687857519, 6.529276587919378, 6.486164773217138, 6.391287258802748, 47.80378754230321, 28.74785309255749, 38.340690091467785, 34.43177003525034, 15.866645826496237, 14.913916211797941, 12.106682461213836, 10.829068618383518, 10.595997274692047, 10.56360281691111, 10.537570139114331, 10.395861799337679, 9.988651975427523, 9.33270011142216, 9.179526514817988, 8.522688629222651, 8.207892865380192, 8.129982129221824, 7.4120000508635275, 7.115634487997263, 7.070636839022529, 6.343562314498607, 6.074530777715392, 5.802874968915603, 5.280368738007674, 15.74058191062891, 4.943687569352262, 4.718386935810969, 4.301108590769171, 4.2757996439854145, 4.008460428724042, 3.6701338757651167, 3.613863233047748, 3.446070747664003, 48.62904779581592, 27.137764475519234, 13.65042047718141, 76.66414875268207, 23.626948106641052, 55.86792058229566, 45.10027241019801, 14.350567274512478, 11.107076081738331, 9.952512411939969, 9.232936409335917, 8.638467312727931, 7.058741976774501, 6.269910882982825, 5.447349945957235, 3.492927612251769, 3.468769719820152, 3.4336196556738354, 3.1658488703411125, 3.0741097597202782, 2.91586034631583, 2.546006661267774, 2.0806341267557245, 1.8434598363583787, 1.6821975443500177, 1.5156548232548628, 1.409693751415625, 1.4032304028476097, 1.306423929179209, 1.306423929179209, 1.281546611475593, 1.281546611475593, 1.25491380394446, 1.2107174015335374, 1.1373549237375964, 1.0616539949985304, 72.35857081027112, 29.7720463365949, 27.291806599991915, 8.92265723728632, 65.34571374561938, 119.76436356134296, 17.724392319354273, 8.881322712016797, 7.096260314846238, 6.019823482600314, 5.0835930881615905, 4.537628808933882, 3.832558218945563, 3.618357672055084, 3.4112711978315278, 3.2701636547505712, 3.150495303505106, 3.0976949941068406, 3.070045697981589, 2.9866158763227437, 2.8976603685477262, 2.746993806972069, 2.6256382071872455, 2.4686102126444207, 2.4186397871161494, 2.1714074123836102, 2.053890518898304, 1.7401485907647085, 1.6951487914667285, 1.6755030592327016, 1.6387273037610195, 1.6355315226433491, 1.415816620750429, 1.4154332730832775, 1.2890755989534244, 12.048274561873683, 6.969635735986107, 6.336125679296629, 4.734381355408887, 4.106358960380842, 3.751383463027926, 3.6423946641878953, 2.469268066297311, 2.232777215583995, 2.0925452688257526, 2.037016879782135, 1.9983134672166372, 1.94636678188757, 1.6450237413295363, 1.5391692905060261, 1.3986332027554669, 1.3159039837677469, 1.212653683731937, 1.1765376578907505, 1.1412902560305993, 5.9631903153317, 1.0357733943046437, 0.9493094026313988, 0.769766851940479, 0.7697670624649716, 0.7697942035450469, 0.7697724779890962, 0.7697987334455951, 0.7698091151238082, 0.7697606131053201, 0.7697598156906534, 0.769769206473386, 0.7697799837270725, 0.7697832857537852, 0.7698478139186434, 21.20821475690619, 25.83607398525908, 9.191070991248836, 5.131312962485177, 4.665501058498091, 4.010002469818692, 3.354893757631199, 2.8906749936820706, 2.6845256890019806, 2.0601681538480348, 2.0240392446674407, 1.8772327887373403, 1.8235704167702302, 1.8232284803353582, 1.6856346072528392, 1.6844457648089861, 1.3971074901948042, 1.3313160005665403, 1.3313160005665403, 1.3313160005665403, 1.3313160005665403, 1.1517490500589582, 1.1331820531242065, 1.097958892200884, 1.0124018773616037, 1.0026249795624411, 0.7697608509564396, 0.7697608509564396, 0.7697636035772818, 0.7697661445965104, 0.769773025486984, 0.7697856133606409, 5.704001560951194, 3.2851770833624547, 3.1028059565433503, 2.7685778431461907, 2.251453169349731, 1.8945555755572032, 1.806915349591503, 1.7317423067280728, 1.7317423067280728, 1.3441067395314525, 1.257177701675623, 1.234881868523911, 1.1690840983760973, 1.141440590399041, 3.219969942377015, 1.0514707007723192, 14.04896246354645, 8.382402124876354, 0.7698021490684579, 0.7697860205071857, 0.7697736196176989, 0.7697697455603261, 0.7697711912430291, 0.7697713766204708, 0.7697719266424472, 0.7697727258582898, 0.769789927646334, 0.7697703534315489, 0.7697634373412009, 0.7697672840327737, 13.94375022880226, 2.2086730095971516, 2.020171685348058, 1.391171625027168, 1.337732169333101, 1.2216567709151023, 8.827863012925997, 1.0147852582463097, 13.785665208898324, 0.9124135313677177, 0.8950780853107704, 0.8941417561290398, 0.7697662205191554, 0.7697598961017176, 0.7697598961017176, 0.7697598961017176, 0.7697621454756524, 0.7697601355465576, 0.7697625478737873, 0.7697617403557455, 0.76976436778535, 0.7697631426074533, 0.7697722726652612, 0.7697588198324757, 0.7697660606441815, 0.7697668059361374, 0.7697675472894899, 0.7697586849289282, 0.7697586849289282, 0.7697586849289282, 0.7697602448103625, 0.769763003633302, 0.7697602448103625, 0.7697711029672974, 0.7697784503812078, 0.7697686435305626, 0.7698072502316841, 0.7698098995917124, 7.214928498319814, 1.3467841179967108, 0.930178880395229, 0.9109293875217047, 0.7928222666593645, 0.7697600439713627, 0.7697593914249051, 0.7697593914249051, 0.7697593914249051, 0.7697593914249051, 0.7697639539103679, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697587734038485, 0.7697592422595, 0.7697595770171477, 0.7697597116221835, 0.7697597860333335, 0.7697617355406603, 0.7697613271768137, 0.7697901906558658, 0.7697689581806596, 0.7697613475313153, 0.7697622279403283, 0.7697751540384792, 0.7697685068602234, 0.7697656462951319, 0.7697696735928323, 0.7697631275095937, 0.7697615787984097, 3.427872510252219, 1.989358368903525, 1.3245261814836262, 1.1052767197159226, 1.0252887497861867, 0.9060851687230301, 0.8831933678563062, 0.8750841879435187, 0.7697606677002754, 0.7697606677002754, 0.7697594426626825, 0.7697594426626825, 0.7697627808936349, 0.7697632911798311, 0.7697599939151427, 0.7697593956498308, 0.7697587692534701, 0.7697599893685877, 0.7697590789621983, 0.7697644324350515, 0.7697604708797628, 0.7697614936782613, 0.7697583246834946, 0.7697583246834946, 0.7697583246834946, 0.7697586225867654, 0.7697647220678776, 0.7697590371215414, 0.7697593147871699, 0.7697604502381585, 0.7697752329252409, 0.7698098350593561, 0.7697722100556373, 0.7697782668345666, 0.7698478139186434, 0.7697946253766992, 0.7697732204693146, 0.7698541854267809, 0.7697933763139171, 0.7698644323590341, 0.7698057690304221, 0.7698038298767588, 0.769793894075685, 0.7697777660213049, 1.1106049622659537, 1.0512597004673916, 0.9333152703347889, 0.7697598604191747, 0.7697590799073906, 0.7697586056665884, 0.7697586056665884, 0.7697586056665884, 0.7697624431633509, 0.7697591679505394, 0.7697594934611593, 0.7697595856984886, 0.7697671100270217, 0.769759380723979, 0.7697602874392873, 0.7697602874392873, 0.7697602874392873, 0.7697602874392873, 0.7697602874392873, 0.7697602874392873, 0.7697602874392873, 0.7697602874392873, 0.7697586973329335, 0.7697605922516172, 0.7697588542483723, 0.7697588542483723, 0.7697587510130847, 0.7697587510130847, 0.7697587510130847, 0.7697587510130847, 0.7697608980841589, 0.769764972683435, 0.7697616294141535, 0.7697617259574524, 0.7697660044501569, 0.7697631474528326, 0.7697631474528326, 0.769763758255391, 0.7697842566149733, 0.7697677100836526, 0.7697818462412662, 0.7697634390829201, 0.7697704029300652, 0.7697942035450469, 0.7697683750673949, 0.769787499675189, 0.7698091151238082, 62.91473440708881], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.6861, -4.9635, -4.9828, -5.1387, -5.107, -5.2173, -5.3274, -5.443, -4.4102, -5.5313, -5.7108, -5.7186, -5.7943, -5.7985, -5.81, -5.9082, -5.9615, -5.9839, -5.9849, -6.0079, -6.0188, -6.0305, -6.0352, -6.0422, -6.0589, -6.0823, -6.0843, -5.821, -6.1007, -6.1424, -4.5079, -4.5151, -5.1014, -3.9002, -4.7068, -4.3805, -5.6499, -4.3413, -4.7675, -4.8858, -5.1023, -5.2101, -5.5923, -5.273, -5.206, -4.252, -5.0457, -4.4392, -4.9972, -3.8999, -5.0669, -4.8472, -4.6182, -4.711, -4.672, -4.7513, -5.0767, -5.1565, -4.2972, -4.4648, -4.6599, -4.6716, -4.7233, -4.7854, -4.8894, -4.9882, -5.0068, -5.0708, -5.0936, -4.3775, -5.2484, -5.3499, -5.4202, -5.4442, -5.4688, -5.0258, -5.521, -5.5804, -5.6656, -5.6886, -5.7182, -5.7525, -5.7996, -5.8341, -5.8373, -5.8994, -5.9252, -5.9328, -4.357, -5.1792, -5.1498, -5.0715, -4.3625, -5.2802, -4.7621, -5.3848, -4.7653, -5.1579, -5.0185, -5.0347, -4.3739, -4.959, -4.4378, -4.7474, -5.0773, -5.024, -4.766, -4.5066, -4.9772, -5.1008, -4.0486, -4.0821, -4.8085, -4.8322, -5.0062, -5.0415, -5.0461, -5.0559, -5.0775, -5.1827, -5.2, -5.2141, -5.2596, -5.1068, -5.418, -5.4411, -5.4757, -5.4768, -5.5105, -5.5254, -5.5585, -5.6171, -5.6684, -5.7157, -5.7431, -5.7442, -5.7546, -5.7877, -5.7991, -5.8127, -5.1742, -4.39, -4.5731, -5.2649, -4.6, -4.3442, -5.2348, -5.2474, -4.4252, -4.9483, -5.2641, -5.2211, -5.0315, -5.2226, -4.6309, -4.9187, -4.9681, -5.1267, -5.0947, -5.0633, -4.9478, -5.1427, -0.4983, -3.9178, -4.5863, -4.603, -4.723, -4.7882, -5.1748, -5.2264, -5.2359, -5.4684, -5.5309, -5.5784, -5.6227, -5.6563, -5.684, -5.6865, -5.7021, -5.7429, -5.7665, -5.7668, -5.8215, -5.8622, -5.9067, -5.9145, -5.9475, -5.9791, -5.9941, -5.9951, -6.0156, -6.0321, -3.4094, -4.2032, -4.2688, -4.4993, -4.5002, -4.6241, -4.6704, -4.7937, -4.8133, -4.8153, -4.834, -4.8666, -4.8894, -5.0085, -5.0549, -5.0902, -5.1357, -5.1595, -5.1988, -5.2859, -5.289, -5.3718, -5.3743, -5.383, -5.4, -5.4169, -5.4393, -5.4604, -5.5196, -5.53, -4.9258, -4.3401, -3.9174, -4.5176, -5.0247, -3.7692, -4.6126, -4.4716, -4.3721, -4.8848, -4.9528, -4.8825, -4.3591, -4.4603, -4.5755, -4.5782, -4.7297, -4.7747, -4.794, -4.8681, -4.9076, -4.9256, -4.948, -4.9633, -4.9701, -5.0059, -4.7013, -5.0893, -5.1019, -5.1442, -5.1952, -5.2521, -5.2595, -5.2854, -5.3051, -5.2852, -5.3277, -5.354, -5.3712, -5.4323, -5.4367, -5.483, -4.7796, -3.528, -5.1909, -4.907, -3.908, -5.1348, -4.744, -4.9201, -4.6754, -4.5364, -4.8861, -4.7643, -4.8425, -5.0954, -4.9442, -3.3542, -3.5916, -3.7814, -3.9829, -4.1245, -4.2164, -4.2177, -4.3003, -4.7129, -4.8579, -4.9281, -4.9526, -5.038, -5.0586, -5.1623, -5.1219, -5.2072, -5.2221, -5.2439, -5.2681, -5.2866, -5.3011, -5.3743, -5.4201, -5.4348, -5.499, -3.7746, -4.3918, -5.5342, -5.5494, -4.4923, -4.2582, -3.8786, -3.1075, -4.2721, -4.1591, -4.1587, -4.3126, -4.6641, -4.8488, -4.934, -5.0271, -5.1129, -2.5437, -2.5694, -2.86, -3.6268, -4.0484, -4.2204, -4.3114, -4.51, -4.5218, -4.648, -4.803, -5.0524, -5.2859, -5.5037, -5.6686, -5.6987, -5.8576, -5.9296, -5.9329, -6.0177, -6.3078, -6.3157, -6.3312, -6.3691, -6.387, -6.387, -6.6413, -6.6644, -6.8248, -6.9922, -3.5309, -3.1624, -5.1758, -4.841, -5.0808, -3.603, -4.5403, -5.0634, -4.7655, -4.102, -4.8899, -5.4172, -5.514, -5.4091, -5.2958, -5.487, -5.4956, -5.4895, -2.9718, -3.5263, -3.7392, -3.7917, -4.1235, -4.1739, -4.2133, -4.2709, -4.3126, -4.4038, -4.4221, -4.5094, -4.6126, -4.7364, -4.6865, -4.7524, -4.8528, -4.8859, -4.9153, -4.9634, -5.0381, -5.0821, -5.1319, -5.1402, -5.1507, -5.1955, -5.2629, -5.2276, -5.3024, -5.3126, -4.0961, -4.1156, -4.4179, -4.8819, -5.0538, -3.8583, -4.0367, -4.043, -4.0623, -4.1415, -4.1691, -4.3181, -4.3569, -4.3613, -4.3821, -4.3867, -4.4798, -4.619, -4.7524, -4.7961, -4.8263, -4.9114, -4.9205, -4.9243, -4.964, -4.9681, -4.9749, -4.9749, -5.0277, -5.0898, -5.0946, -5.1035, -5.3194, -5.3269, -5.3435, -4.7276, -4.9186, -4.8412, -4.9788, -4.0212, -4.0863, -4.307, -4.4262, -4.4495, -4.4528, -4.4555, -4.47, -4.5131, -4.5866, -4.6046, -4.6856, -4.7269, -4.7374, -4.8395, -4.885, -4.892, -5.014, -5.0631, -5.1154, -5.2242, -4.1407, -5.3012, -5.3563, -5.467, -5.4741, -5.5527, -5.6618, -5.6812, -5.7413, -3.2026, -3.9377, -4.9118, -4.0095, -4.7449, -5.1099, -2.3984, -3.5803, -3.8527, -3.9708, -4.0523, -4.1249, -4.3482, -4.4817, -4.643, -5.1806, -5.1894, -5.2024, -5.3074, -5.3461, -5.4165, -5.6035, -5.9029, -6.0987, -6.2578, -6.454, -6.6024, -6.6122, -6.7718, -6.7718, -6.8173, -6.8173, -6.8685, -6.9596, -7.1319, -7.3476, -3.6752, -5.3528, -6.1741, -6.4677, -6.3513, -6.3005, -3.0468, -3.7828, -4.0308, -4.2167, -4.4123, -4.547, -4.7531, -4.8268, -4.9002, -4.9547, -5.0033, -5.0256, -5.0375, -5.0741, -5.1147, -5.1875, -5.2502, -5.3378, -5.3673, -5.5278, -5.6142, -5.8898, -5.9364, -5.9575, -5.9981, -6.0017, -6.2874, -6.288, -6.4991, -4.3405, -3.6579, -3.7654, -4.1037, -4.2755, -4.3875, -4.4246, -4.9462, -5.0948, -5.1945, -5.237, -5.2677, -5.3104, -5.6023, -5.7291, -5.9269, -6.0647, -6.2686, -6.351, -6.4385, -4.9974, -6.7586, -7.1284, -9.7765, -9.7765, -9.7765, -9.7765, -9.7765, -9.7764, -9.7765, -9.7765, -9.7765, -9.7765, -9.7765, -9.7765, -9.7752, -9.7764, -3.3176, -3.9741, -4.0867, -4.2702, -4.4951, -4.6919, -4.7935, -5.1848, -5.2129, -5.336, -5.3851, -5.3854, -5.5236, -5.5248, -5.8954, -6.0038, -6.0038, -6.0038, -6.0038, -6.3784, -6.4265, -6.5247, -6.8133, -6.8522, -9.7801, -9.7801, -9.7801, -9.7801, -9.7801, -9.7801, -3.5622, -4.234, -4.3089, -4.4628, -4.7604, -5.0338, -5.1141, -5.1886, -5.1886, -5.6973, -5.8583, -5.9041, -6.0531, -6.1229, -5.2572, -6.3915, -4.741, -6.1856, -9.7387, -9.7388, -9.7388, -9.7389, -9.7389, -9.7389, -9.7389, -9.7389, -9.7388, -9.7389, -9.7389, -9.7389, -7.792, -4.5004, -4.6399, -5.3327, -5.4214, -5.6465, -3.6715, -6.2438, -3.7362, -6.7622, -6.8844, -6.8914, -9.6903, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -9.6904, -3.1961, -4.97, -6.2264, -6.3498, -7.9889, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -9.652, -3.3798, -4.1567, -4.9396, -5.4368, -5.7046, -6.3164, -6.4932, -6.5642, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -9.6703, -4.752, -4.9416, -5.4779, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619, -9.619], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7602, 0.7598, 0.7595, 0.7594, 0.7594, 0.7593, 0.7591, 0.7588, 0.7588, 0.7585, 0.7579, 0.7579, 0.7576, 0.7576, 0.7575, 0.7572, 0.7569, 0.7568, 0.7568, 0.7567, 0.7567, 0.7566, 0.7566, 0.7565, 0.7565, 0.7563, 0.7563, 0.7563, 0.7562, 0.756, 0.7555, 0.7497, 0.7547, 0.7414, 0.7481, 0.7426, 0.7541, 0.7375, 0.7346, 0.7368, 0.7384, 0.7356, 0.7462, 0.7331, 0.7272, 0.6734, 0.7049, 0.657, 0.6912, 0.5716, 0.6886, 0.6626, 0.6181, 0.6104, 0.5712, 0.5493, 0.2903, 0.5408, 1.7764, 1.7759, 1.7753, 1.7753, 1.7751, 1.7749, 1.7745, 1.774, 1.7739, 1.7736, 1.7735, 1.7734, 1.7726, 1.772, 1.7715, 1.7713, 1.7711, 1.7707, 1.7707, 1.7702, 1.7695, 1.7693, 1.769, 1.7686, 1.7681, 1.7678, 1.7677, 1.767, 1.7667, 1.7666, 1.7661, 1.7552, 1.7514, 1.7266, 1.5921, 1.7, 1.6111, 1.7023, 1.5098, 1.6193, 1.5568, 1.5487, 1.2475, 1.4528, 0.9568, 1.1785, 1.4383, 1.2544, 0.601, -0.035, 0.8439, 0.9966, 2.3122, 2.312, 2.3085, 2.3084, 2.307, 2.3067, 2.3067, 2.3066, 2.3064, 2.3055, 2.3053, 2.3051, 2.3047, 2.3045, 2.3028, 2.3025, 2.3021, 2.3021, 2.3016, 2.3014, 2.301, 2.3001, 2.2993, 2.2984, 2.2981, 2.2981, 2.2976, 2.2973, 2.2971, 2.2968, 2.2882, 2.2718, 2.2719, 2.2822, 2.1826, 2.1117, 2.1899, 2.1819, 1.8923, 2.0223, 2.1575, 2.1061, 1.9485, 2.0962, 1.4265, 1.6747, 1.6864, 1.9392, 1.7934, 1.2136, 0.2886, 1.1867, 2.6293, 2.6259, 2.6225, 2.6224, 2.6215, 2.6209, 2.6169, 2.6163, 2.6161, 2.6127, 2.6116, 2.6108, 2.6099, 2.6093, 2.6087, 2.6086, 2.6083, 2.6075, 2.6069, 2.6069, 2.6057, 2.6047, 2.6036, 2.6034, 2.6025, 2.6017, 2.6013, 2.6012, 2.6007, 2.6002, 2.8145, 2.8111, 2.8107, 2.809, 2.809, 2.8079, 2.8075, 2.8062, 2.806, 2.806, 2.8058, 2.8054, 2.8051, 2.8036, 2.803, 2.8025, 2.8018, 2.8014, 2.8008, 2.7993, 2.7992, 2.7977, 2.7976, 2.7975, 2.7971, 2.7968, 2.7963, 2.7959, 2.7946, 2.7944, 2.7851, 2.7228, 2.6809, 2.6503, 2.7084, 1.8522, 2.2334, 1.4052, 1.0225, 1.527, 1.5628, 1.2149, 2.8135, 2.8127, 2.8117, 2.8117, 2.8102, 2.8097, 2.8095, 2.8087, 2.8082, 2.808, 2.8077, 2.8075, 2.8074, 2.8069, 2.8068, 2.8057, 2.8055, 2.8049, 2.8041, 2.8031, 2.803, 2.8025, 2.8021, 2.802, 2.8017, 2.8012, 2.8009, 2.7996, 2.7996, 2.7986, 2.7969, 2.7052, 2.7644, 2.7042, 2.287, 2.7054, 2.3929, 2.4966, 2.2813, 1.9516, 2.0347, 1.542, 1.7469, 2.3858, 0.8769, 3.9734, 3.9711, 3.9688, 3.9659, 3.9635, 3.9617, 3.9617, 3.96, 3.9489, 3.9438, 3.9411, 3.9401, 3.9364, 3.9355, 3.9306, 3.9303, 3.9283, 3.9275, 3.9263, 3.925, 3.924, 3.9231, 3.9188, 3.9159, 3.915, 3.9107, 3.9088, 3.9085, 3.9082, 3.9071, 3.8883, 3.8169, 3.6262, 3.4165, 3.644, 3.239, 3.2217, 2.6081, 2.8171, 2.3987, 1.4255, 1.9126, -0.0167, 4.2668, 4.2667, 4.2649, 4.2568, 4.2489, 4.2447, 4.2421, 4.2357, 4.2352, 4.2304, 4.2236, 4.2103, 4.1947, 4.1768, 4.1607, 4.1575, 4.139, 4.1297, 4.1293, 4.1176, 4.0706, 4.0692, 4.0663, 4.0591, 4.0557, 4.0557, 4.0009, 3.9954, 3.9542, 3.9057, 3.7985, 3.7824, 3.7378, 3.6385, 3.6085, 2.4944, 2.5944, 2.9643, 2.5253, 1.6464, 2.3002, 2.8421, 3.0253, 1.9644, 1.2796, 1.8227, 1.6964, 0.5586, 4.4846, 4.4773, 4.4733, 4.4722, 4.4635, 4.4619, 4.4606, 4.4587, 4.4572, 4.4537, 4.4529, 4.4492, 4.4444, 4.438, 4.438, 4.4372, 4.4313, 4.4292, 4.4273, 4.4241, 4.4189, 4.4156, 4.4118, 4.4111, 4.4103, 4.4066, 4.4007, 4.3984, 4.3971, 4.3962, 4.237, 4.2349, 3.4866, 3.6951, 3.0708, 4.65, 4.6446, 4.6444, 4.6438, 4.6409, 4.6399, 4.6337, 4.632, 4.6318, 4.6308, 4.6306, 4.626, 4.6184, 4.61, 4.607, 4.6049, 4.5986, 4.5979, 4.5976, 4.5944, 4.5941, 4.5935, 4.5935, 4.5891, 4.5836, 4.5832, 4.5824, 4.5604, 4.5596, 4.5577, 3.1615, 3.479, 3.2685, 3.2384, 4.9707, 4.9676, 4.9555, 4.9478, 4.9462, 4.9459, 4.9457, 4.9447, 4.9416, 4.936, 4.9346, 4.9278, 4.9242, 4.9232, 4.9135, 4.9089, 4.9082, 4.8948, 4.8889, 4.8824, 4.8679, 4.8592, 4.8568, 4.8484, 4.8303, 4.8291, 4.8151, 4.7941, 4.7902, 4.7776, 4.6693, 4.5176, 4.2306, 3.4073, 3.8489, 2.6233, 5.5488, 5.5121, 5.4959, 5.4875, 5.4811, 5.4751, 5.4537, 5.4387, 5.418, 5.3248, 5.323, 5.3201, 5.2963, 5.2871, 5.2695, 5.2181, 5.1206, 5.0458, 4.9782, 4.8863, 4.8104, 4.8052, 4.717, 4.717, 4.6907, 4.6907, 4.6606, 4.6054, 4.4956, 4.3488, 3.7993, 3.0097, 2.2755, 3.0999, 1.2251, 0.6702, 5.8345, 5.7894, 5.7658, 5.7444, 5.7178, 5.6967, 5.6595, 5.6434, 5.6289, 5.6167, 5.6053, 5.5999, 5.597, 5.5879, 5.5775, 5.5581, 5.5406, 5.5147, 5.5057, 5.453, 5.4222, 5.3124, 5.292, 5.2826, 5.2642, 5.2625, 5.121, 5.1207, 5.0031, 4.9267, 6.1567, 6.1445, 6.0976, 6.0681, 6.0465, 6.0389, 5.906, 5.8582, 5.8232, 5.8077, 5.7962, 5.7798, 5.6561, 5.5958, 5.4938, 5.4169, 5.2948, 5.2426, 5.1855, 4.9731, 4.9624, 4.6797, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2413, 2.2412, -1.0734, -1.272, 6.2203, 6.1467, 6.1293, 6.0971, 6.0507, 6.0028, 5.9752, 5.8485, 5.8381, 5.7903, 5.7702, 5.7701, 5.7105, 5.7099, 5.5263, 5.4662, 5.4662, 5.4662, 5.4662, 5.2365, 5.2046, 5.138, 4.9306, 4.9013, 2.2378, 2.2378, 2.2378, 2.2378, 2.2378, 2.2377, 6.4528, 6.3328, 6.3149, 6.275, 6.1842, 6.0834, 6.0504, 6.0184, 6.0184, 5.7632, 5.669, 5.6411, 5.5469, 5.5009, 5.3296, 5.3144, 4.3726, 3.4445, 2.2791, 2.279, 2.279, 2.279, 2.279, 2.279, 2.279, 2.279, 2.279, 2.2789, 2.2789, 2.2789, 1.3291, 6.4634, 6.413, 6.0933, 6.0438, 5.9095, 5.9068, 5.4976, 5.3963, 5.0856, 4.9826, 4.9766, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3275, 2.3274, 2.3274, 2.3274, 2.3274, 2.3274, 6.584, 6.4884, 5.6022, 5.4997, 3.9994, 2.3659, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 2.3658, 7.1444, 6.9116, 6.5355, 6.2193, 6.0266, 5.5384, 5.3872, 5.3254, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3475, 2.3474, 2.3475, 2.3474, 2.3475, 2.3475, 2.3475, 2.3475, 6.8993, 6.7645, 6.3472, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, 2.3988, -2.0046]}, \"token.table\": {\"Topic\": [2, 1, 12, 5, 3, 1, 1, 2, 5, 11, 11, 3, 10, 1, 2, 3, 5, 13, 7, 8, 4, 2, 2, 11, 2, 5, 6, 1, 2, 3, 6, 5, 6, 7, 1, 7, 14, 1, 6, 1, 2, 6, 7, 11, 6, 10, 4, 7, 7, 16, 6, 2, 3, 8, 4, 1, 6, 4, 15, 11, 1, 7, 8, 7, 1, 6, 9, 9, 11, 1, 2, 5, 6, 11, 6, 5, 11, 10, 2, 5, 15, 15, 15, 6, 5, 10, 6, 9, 5, 9, 4, 1, 6, 5, 6, 14, 1, 2, 3, 6, 1, 2, 18, 14, 6, 5, 10, 5, 1, 7, 5, 6, 6, 7, 1, 7, 3, 3, 9, 5, 8, 4, 15, 12, 2, 13, 1, 3, 2, 14, 16, 4, 2, 2, 10, 13, 11, 7, 16, 12, 7, 10, 1, 2, 3, 5, 3, 4, 4, 7, 1, 3, 6, 1, 2, 13, 11, 14, 3, 3, 13, 4, 5, 2, 5, 12, 1, 2, 3, 5, 6, 7, 3, 8, 5, 11, 3, 10, 3, 8, 14, 7, 1, 2, 9, 8, 2, 5, 6, 9, 11, 1, 2, 13, 2, 4, 1, 2, 3, 12, 1, 2, 9, 11, 10, 5, 1, 5, 5, 1, 3, 8, 6, 6, 5, 10, 9, 2, 1, 16, 12, 2, 6, 2, 10, 1, 9, 11, 5, 11, 1, 3, 10, 10, 13, 1, 2, 5, 7, 19, 13, 13, 9, 7, 2, 6, 8, 15, 1, 12, 13, 3, 3, 2, 3, 1, 12, 1, 3, 5, 6, 8, 8, 1, 2, 3, 5, 7, 9, 6, 11, 11, 4, 10, 1, 6, 14, 3, 8, 16, 11, 10, 13, 5, 7, 1, 2, 5, 6, 8, 15, 16, 1, 2, 3, 6, 1, 6, 6, 1, 2, 6, 8, 8, 10, 3, 13, 9, 9, 7, 3, 2, 1, 2, 3, 14, 4, 13, 1, 6, 12, 12, 17, 12, 1, 4, 9, 11, 1, 1, 8, 8, 14, 12, 10, 1, 2, 6, 1, 3, 7, 5, 13, 2, 10, 11, 11, 3, 8, 1, 2, 3, 5, 5, 3, 15, 12, 2, 2, 3, 13, 6, 8, 5, 10, 2, 7, 13, 3, 1, 2, 3, 8, 16, 10, 2, 6, 6, 4, 1, 2, 6, 6, 9, 14, 8, 4, 3, 14, 4, 8, 8, 8, 1, 1, 6, 12, 11, 2, 3, 1, 1, 2, 6, 1, 2, 8, 6, 10, 1, 1, 9, 1, 2, 5, 1, 8, 9, 9, 11, 1, 2, 15, 12, 1, 2, 8, 1, 3, 3, 6, 7, 2, 5, 2, 7, 10, 9, 4, 13, 5, 1, 3, 5, 6, 1, 2, 2, 17, 9, 7, 13, 11, 6, 2, 5, 1, 7, 7, 7, 5, 15, 2, 17, 7, 1, 9, 19, 1, 2, 6, 2, 3, 1, 2, 3, 1, 8, 8, 11, 1, 2, 14, 4, 2, 11, 8, 3, 12, 1, 4, 4, 1, 2, 3, 6, 8, 12, 8, 6, 6, 11, 19, 1, 3, 11, 10, 6, 10, 15, 10, 16, 2, 13, 11, 12, 6, 11, 5, 12, 2, 9, 1, 2, 6, 8, 8, 8, 16, 10, 1, 3, 2, 3, 3, 9, 11, 17, 6, 8, 3, 5, 3, 3, 7, 8, 3, 2, 3, 14, 7, 1, 1, 5, 4, 10, 2, 5, 12, 2, 14, 5, 3, 3, 1, 2, 3, 2, 3, 13, 1, 3, 13, 12, 1, 5, 15, 12, 8, 1, 4, 4, 13, 10, 1, 7, 6, 9, 5, 6, 2, 3, 5, 9, 9, 2, 12, 1, 3, 5, 6, 11, 4, 9, 15, 8, 12, 1, 2, 5, 6, 8, 8, 1, 6, 5, 3, 9, 11, 4, 1, 3, 6, 7, 9, 8, 8, 17, 7, 5, 10, 6, 11, 2, 3, 5, 1, 2, 3, 6, 7, 1, 7, 15, 1, 2, 11, 3, 2, 2, 7, 15, 10, 6, 12, 4, 12, 4, 7, 6, 8, 3, 2, 16, 1, 2, 5, 1, 5, 14, 13, 7, 14, 18, 1, 6, 1, 3, 1, 3, 6, 8, 6, 13, 7, 6, 2, 9, 11, 1, 13, 3, 1, 5, 10, 7, 9, 13, 5, 1, 2, 5, 9, 1, 3, 6, 1, 6, 3, 6, 10, 8, 2, 1, 13, 12, 6, 11, 12, 1, 1, 6, 13, 16, 1, 3, 6, 10, 1, 3, 8, 9, 15, 6, 10, 3, 9, 1, 5, 7, 1, 2, 13, 9, 9, 15, 14, 6, 12, 6, 12, 12, 1, 2, 3, 5, 2, 15, 5, 4, 2, 5, 9, 10, 15, 1, 2, 5, 13, 1, 5, 6, 3, 5, 10, 12, 4, 1, 3, 5, 1, 8, 2, 5, 3, 8, 16, 6, 7, 10, 1, 2, 5, 6, 7, 5, 12, 8, 1, 2, 1, 17, 1, 3, 6, 8, 10], \"Freq\": [0.9965212926555916, 0.9526668710897175, 0.03664103350345067, 0.9923162837686279, 0.9880062721101942, 0.9959922831193798, 0.016859767668099216, 0.9272872217454567, 0.050579303004297645, 0.8301365620496802, 0.8715046453742527, 0.9865976314559499, 0.9128300834605702, 0.6248102518755122, 0.3073663335839213, 0.015116377061504326, 0.05206752098962601, 0.6696542450790459, 0.9788110473938179, 0.7709955798034454, 0.9847130281393021, 0.9962582512120057, 0.5128047162870536, 0.4395468996746174, 0.9485672373421585, 0.049184967862186, 0.9885514678874638, 0.013208339925241671, 0.10566671940193337, 0.8717504350659503, 0.9716677635762225, 0.05039500130056707, 0.07559250195085061, 0.8567150221096402, 0.4273777380521487, 0.566275502919097, 0.6497011122611693, 0.09506062432225988, 0.8872324936744256, 0.9757756397269879, 0.021404110806914574, 0.00125906534158321, 0.9474618022927592, 0.9437526021155598, 0.7551165674428554, 0.23234355921318628, 0.9621715914967471, 0.9698629019240281, 0.8900142320909444, 0.4441575839167119, 0.9890243130047217, 0.9952949218224927, 0.7209238541468542, 0.2643387465205132, 0.9998839635884642, 0.6558388398141097, 0.3421767859899703, 0.9754206799401877, 0.7511364691586753, 0.8432136319144654, 0.9199235464192512, 0.07703793245875502, 0.6565077435353325, 0.9771173007186321, 0.4116714321311469, 0.5845734336262286, 0.9907295815016307, 0.8951247780403815, 0.8231088429649016, 0.015459545740354165, 0.530777737085493, 0.03091909148070833, 0.41740773498956246, 0.8485798573172741, 0.994161264427419, 0.3684901904510566, 0.5895843047216905, 0.9714765957388751, 0.017505971534743228, 0.9628284344108775, 0.4940615665603385, 0.7481292150265538, 0.7795275847027533, 0.9702907059245693, 0.9691831536316994, 0.9387780203019624, 0.7412842810986665, 0.23826994749599995, 0.9880522635414148, 0.8635939373391655, 0.9959106346837275, 0.10783461814694234, 0.8906340683988201, 0.9944027781342989, 0.984279015494978, 0.5137777778092824, 0.19286729096771218, 0.0367366268509928, 0.6888117534561149, 0.0734732537019856, 0.9943036951615374, 0.4158045364827425, 0.4158045364827425, 0.730574221334456, 0.9862365726351628, 0.9920434531669637, 0.8973955956128865, 0.9798629009323852, 0.866216336374984, 0.12952767646728733, 0.8746208328277215, 0.1265898573829597, 0.9916795047912061, 0.9903501268108315, 0.0631230955223245, 0.9152848850737052, 0.9897274551092284, 0.6160715362273397, 0.3611453833056819, 0.9926096713079453, 0.7950912500778643, 0.9732896536407255, 0.5936670808237027, 0.7968674795486256, 0.9922020793341249, 0.5899187168901848, 0.9970207527950258, 0.9833701823153836, 0.9963727547314941, 0.6078939621818363, 0.5278282742937707, 0.9676937879024194, 0.9990172441906406, 0.7739972479640328, 0.20918844539568454, 0.6902120143922791, 0.9643511408863366, 0.9476612254952443, 0.5534293569569124, 0.7654483186237051, 0.9513524322441341, 0.8721305625079177, 0.15479560371127313, 0.22850779595473653, 0.058969753794770714, 0.5602126610503219, 0.9826338917350265, 0.9749761939323867, 0.9523368949804927, 0.9792369298365263, 0.029456263384128774, 0.9573285599841851, 0.0073640658460321935, 0.9968024826905294, 0.580996055829541, 0.4149971827353864, 0.8610105026971342, 0.946950913490412, 0.9972280107958579, 0.9911286029675673, 0.7868450386627116, 0.975999790802967, 0.9678478733619367, 0.7098339735287381, 0.28605249679516315, 0.5424582517487484, 0.9707138467949277, 0.009548005050441911, 0.01591334175073652, 0.10242900678188191, 0.40971602712752764, 0.4737341563662038, 0.7270191034055866, 0.24233970113519554, 0.8949679794569769, 0.08949679794569769, 0.7302946278014707, 0.234737558936187, 0.9909871002022029, 0.8478714803719091, 0.8099566131752626, 0.9780121930899008, 0.00701563845765919, 0.9892050225299459, 0.9285142308642176, 0.9468150983800941, 0.7209908895442747, 0.2769368979706485, 0.7174148659424833, 0.06521953326749848, 0.19565859980249545, 0.9936423437381867, 0.9861140918738697, 0.7280686235709215, 0.9921634787278619, 0.9885608660398403, 0.20039350008909176, 0.04174864585189412, 0.7431258961637153, 0.008349729170378824, 0.16927515912462876, 0.8312619421298734, 0.9669081901732229, 0.8705567063687296, 0.9760862121708606, 0.9971464912205762, 0.0824155545698544, 0.9065711002683984, 0.9948598620343068, 0.6759312879421098, 0.17678202915409025, 0.13518625758842195, 0.9878409343005796, 0.9773494435169081, 0.9901823534280089, 0.9189379434624261, 0.9360604864639992, 0.9920693858108743, 0.8541556026743614, 0.14235926711239358, 0.6597808317942102, 0.9907250473309858, 0.9768464026210236, 0.994573495736721, 0.8884057587274503, 0.9971714436561543, 0.9696398780437342, 0.9619212137503695, 0.9903249192134912, 0.9234404501809063, 0.9765031510407007, 0.02158018013349615, 0.9418430728503958, 0.9654426638412631, 0.6514561009026368, 0.5836910072871759, 0.11013037873342942, 0.09911734086008649, 0.2092477195935159, 0.8751784061476847, 0.5746635691383974, 0.5968356754048251, 0.9711054155917627, 0.9775266944423618, 0.0446991527157428, 0.9386822070305988, 0.9778285421105449, 0.7511364691586753, 0.994332593662451, 0.6317420956940705, 0.8815176755147148, 0.9828029774391929, 0.9719792264791101, 0.9931941799037862, 0.003678496962606616, 0.9951671540331593, 0.9756038633161511, 0.8928283765785101, 0.06638129193892268, 0.009957193790838403, 0.006638129193892268, 0.023233452178622938, 0.9163444743740582, 0.43392507351280557, 0.20861782380423344, 0.3337885180867735, 0.020861782380423344, 0.9366540491915996, 0.05109022086499634, 0.6771928362386646, 0.29627186585441573, 0.9010224825272073, 0.9673537976854605, 0.9508337825381057, 0.345096474483066, 0.6507533518823531, 0.7599338647313473, 0.9878551399681915, 0.9959826465385159, 0.9131927819639575, 0.9085891230104273, 0.9696969033458263, 0.611422027735545, 0.9878551801783286, 0.9702093731934144, 0.9158467484326036, 0.018360135286974364, 0.018360135286974364, 0.04428032628034994, 0.002160015916114631, 0.7511364691586753, 0.8765776002288128, 0.9441410636965734, 0.027116322978230564, 0.012325601353741167, 0.0147907216244894, 0.988770197543739, 0.010615630955224192, 0.9850545779023498, 0.9066987697644349, 0.03293563907263973, 0.0581217160105407, 0.00193739053368469, 0.8066276762229666, 0.9447616696214285, 0.9982245121353276, 0.6348208161982929, 0.9406226205695473, 0.8754313658807186, 0.936914930408098, 0.9778643355204921, 0.9946674427572586, 0.2990029885627527, 0.3737537357034409, 0.32538560520064264, 0.8448833542803056, 0.9883641018916006, 0.900766728043298, 0.5389824531258438, 0.2764012580132532, 0.16584075480795193, 0.5944605039751076, 0.7475337910865443, 0.8500098204101952, 0.9972699808816907, 0.9703675105284087, 0.9754118403732852, 0.8528376423533836, 0.9957379193930471, 0.8067187814725867, 0.18692264448755058, 0.9246550963257085, 0.49091394868900295, 0.7803071624906286, 0.9425039298323131, 0.8094679135008251, 0.1901856651137861, 0.9827035951524494, 0.4780073616201399, 0.05031656438106736, 0.46542822052487304, 0.9816129845877095, 0.8101724564517471, 0.9935013791932555, 0.9470878534953624, 0.9453793929748532, 0.9458407914251312, 0.9659055301390427, 0.02972017015812439, 0.12118737217599301, 0.5934002361721037, 0.12536624707861346, 0.15879724629957706, 0.9934041494082263, 0.9859804790085225, 0.5326989843772213, 0.8648599481419433, 0.988924210838983, 0.8453262068277233, 0.15160741752888515, 0.610229656700608, 0.681382209358415, 0.2805691450299356, 0.9935060318192986, 0.9635974276740703, 0.9944040900929306, 0.937950805886086, 0.7757496928899132, 0.9930729001706855, 0.034930443622242444, 0.14471183786357583, 0.8133803300607884, 0.7527237157464632, 0.743988532003488, 0.8973955956128865, 0.4113429948688419, 0.5881820393918954, 0.9851285857450214, 0.9709695858994082, 0.9817490646272695, 0.010528140103241495, 0.007896105077431123, 0.9905003239837947, 0.9577991432574463, 0.50042198904502, 0.6681244467833458, 0.9910193793122438, 0.9945638894978351, 0.7997049700641781, 0.9733829354493263, 0.756399170101745, 0.9089212373759114, 0.9754431190675842, 0.9952482242394368, 0.9850581386977318, 0.013311596468888269, 0.7855438991680045, 0.9387205748765727, 0.39978935100402985, 0.5919957697559673, 0.9984167389906409, 0.8273624612476734, 0.16327716896927552, 0.009604539351133855, 0.14621377596356439, 0.7985521610317746, 0.05061246091046459, 0.9911895092781459, 0.9602927426168337, 0.9984578077445977, 0.9984176748344803, 0.9828102615372843, 0.928979047151605, 0.039636439345135145, 0.029727329508851357, 0.9023771884977891, 0.08203428986343538, 0.9034406360570099, 0.9077106689654366, 0.8616418631770661, 0.9974183868130396, 0.997070755443666, 0.7450105648806568, 0.7126413438382433, 0.6995949574788649, 0.1873915064675531, 0.09994213678269498, 0.9976351374876183, 0.0013779490849276496, 0.2859495544356771, 0.45275346118982207, 0.25417738172060184, 0.9889176958530386, 0.9812648456598271, 0.9845253493739811, 0.923287908228808, 0.06839169690583763, 0.8949599256735119, 0.9692688677712309, 0.9591302028130314, 0.9869807539382232, 0.14418818035647182, 0.852021065742788, 0.9962365919641738, 0.9911045448258757, 0.20407448294778083, 0.7936229892413699, 0.7253911834116814, 0.21761735502350443, 0.921500071881497, 0.9571006619472913, 0.8794375545125336, 0.9444144565520439, 0.9800875145640287, 0.8265154496804328, 0.17483980666316845, 0.27942111612228887, 0.7092997563104256, 0.9371258842202863, 0.9289464596598979, 0.9944656943250956, 0.8704099889574458, 0.5663884897940604, 0.3398330938764363, 0.9014110932571874, 0.9990936763314366, 0.8820862973197027, 0.5026746390350826, 0.46287249231906663, 0.39145787921841063, 0.142829226201312, 0.9287778181309134, 0.06567115885774136, 0.4258998082326237, 0.5492638906172457, 0.02349792045421372, 0.9168303332199368, 0.07292968559704043, 0.8066276762229666, 0.8174088743219446, 0.8601689441326045, 0.13961697414092647, 0.823633976157517, 0.9785847725749398, 0.986371853509726, 0.8477473455263591, 0.7613061934001414, 0.9742750837177167, 0.6505948571536969, 0.9927299549550479, 0.9950440330366, 0.9608846717670066, 0.8266513581817136, 0.16473662613675083, 0.005936454995918949, 0.0029682274979594744, 0.9757202019124154, 0.8664632404389541, 0.8736177682142838, 0.9812765529117093, 0.9809746026804699, 0.9354975286614821, 0.7549869636248954, 0.866675085183152, 0.13118041255323218, 0.001473937219699238, 0.9181500084972071, 0.9885852670807328, 0.8830714175962701, 0.4853972711558396, 0.6211238104053789, 0.31056190520268945, 0.989413793843749, 0.8291054317734484, 0.9466467239748121, 0.873713544551358, 0.9872716567232032, 0.7484170177912791, 0.9701397788772662, 0.9260902091060514, 0.19567526311912384, 0.7827010524764954, 0.16273684404639627, 0.10577894863015756, 0.11391579083247738, 0.6102631651739859, 0.9936741263746414, 0.9564092927971082, 0.7223925471162534, 0.9464654017086385, 0.9985584779849455, 0.989594967720878, 0.30339795151376975, 0.6910731117813644, 0.9850954566307332, 0.9417138036720616, 0.9386709227613393, 0.45276054701388047, 0.34963263752019674, 0.5827210625336613, 0.880976637242528, 0.10519124026776454, 0.9951426634699172, 0.7590165953404995, 0.06900150866731813, 0.17250377166829534, 0.9946359304795814, 0.013652868492462418, 0.9693536629648317, 0.8608771286310393, 0.9410702586952673, 0.9937886895201826, 0.7550856626050784, 0.24330538017274747, 0.9807724240227113, 0.8759476381752276, 0.974353092975996, 0.016105009801256134, 0.9178775091750371, 0.9975867342681074, 0.44787271789605954, 0.9715540579430404, 0.973134271293231, 0.9955729954750284, 0.09734848702431344, 0.37221480332825724, 0.5268271062492257, 0.11761843301725541, 0.8786788819524375, 0.9173852799819042, 0.17890375083520627, 0.8110303371196017, 0.8269110640839528, 0.9569514004233473, 0.9984951267402222, 0.9762219785286625, 0.8942160964638773, 0.8588783774038776, 0.9786782076536142, 0.9974972237676121, 0.996779174760342, 0.9733216920475248, 0.7063061595293092, 0.9710981107135396, 0.2848996428896761, 0.6980041250797065, 0.8350828194254943, 0.9531943340079269, 0.09960164277247852, 0.8964147849523066, 0.9737510321955238, 0.023370024772692573, 0.9840452263499336, 0.9366688098344851, 0.958898145135802, 0.9937343508257945, 0.9042942754035408, 0.5494338843956733, 0.412075413296755, 0.01340082644867496, 0.023451446285181178, 0.9489853797395921, 0.9869353875475116, 0.9280772214358082, 0.8573570019267497, 0.9189756507867525, 0.48062270398269036, 0.1464507883897528, 0.4567869828347052, 0.20224156491918244, 0.02440846473162547, 0.16737232958828893, 0.7909402141928225, 0.9675286237756483, 0.03254683443893618, 0.966467045277951, 0.990079187930614, 0.1270601056146145, 0.8258906864949943, 0.9970166745378705, 0.9006563745246298, 0.07943199889121913, 0.0012811612724390182, 0.017936257814146254, 0.9505842964860819, 0.9675068707512813, 0.8974207915996668, 0.49500743290920285, 0.9703125643508294, 0.9933729387155339, 0.9687867548925824, 0.9885340351035423, 0.9299927950167557, 0.03678547946117422, 0.9564224659905297, 0.9867062059868942, 0.986685103426777, 0.009169935905453317, 0.0018339871810906633, 0.0018339871810906633, 0.924841404187221, 0.9967270211589643, 0.9457934943832689, 0.5932483799853567, 0.2332371173248061, 0.762185579829277, 0.9469035683077203, 0.9924474170707646, 0.9899104015403233, 0.9919498294942475, 0.9760303842962985, 0.5483747656814505, 0.8917669300639155, 0.9794062430650305, 0.015303222547891102, 0.9723063212112669, 0.9003269561141723, 0.9877889630612036, 0.996235619364978, 0.9886998999712278, 0.8782940024368915, 0.982631908048206, 0.9972109384459553, 0.577453121122498, 0.14450709076248272, 0.8532799645022789, 0.9698999115896166, 0.14238483220981946, 0.8441386481010725, 0.714983741291059, 0.7827669740723152, 0.670781878236516, 0.335390939118258, 0.7425094984691839, 0.7175970606309434, 0.2793042451557564, 0.3433043921776586, 0.6561894078332462, 0.18922109287045477, 0.8041896446994328, 0.46568136056176607, 0.5122494966179426, 0.984838225555938, 0.8455157694042412, 0.9591873192725627, 0.9727143097163079, 0.1991082022178914, 0.763248108501917, 0.809112619656119, 0.9911300682006936, 0.6456413571397014, 0.9948813583744195, 0.9949616685649988, 0.004737912707452375, 0.8800977532688232, 0.9026638971041825, 0.9355201926132702, 0.4868808686727834, 0.9889891979428028, 0.030327001859012603, 0.5870441074137439, 0.38125373765615844, 0.8906431600792202, 0.9760184733516815, 0.004337859881563029, 0.01952036946703363, 0.9962306722345209, 0.9697543627326628, 0.9919195803166104, 0.6609189193651088, 0.31306685654136734, 0.9926006022527017, 0.9980121383392478, 0.9981085891220761, 0.7064974513575425, 0.7654483186237051, 0.28789377202661515, 0.6991705892074939, 0.7803071624906286, 0.9977803152649583, 0.9933773277864074, 0.004542884120974424, 0.8305891384443398, 0.6445778524378236, 0.9729252295810246, 0.021150548469152708, 0.0038455542671186746, 0.9666414816023294, 0.4625798110646094, 0.5356187286011266, 0.9853120794634072, 0.9030680319721771, 0.5484776103410054, 0.9691464487357311, 0.9522605729337283, 0.9752482828965341, 0.9630520424109116, 0.998734027270584, 0.9676392788727843, 0.9831770197920803, 0.9737275282452855, 0.02396867761834549, 0.7617195676560976, 0.9737733531599868, 0.9852538652314253, 0.7511364691586753, 0.47788691355822255, 0.9880029440498217, 0.975571190475856, 0.9904864896706655, 0.7093739324557498, 0.6859039056952733, 0.3401540249827143, 0.4403008952821936, 0.053526775504894125, 0.16576033704741408, 0.9937412464309262, 0.6918799257513378, 0.9845300268769288, 0.9883562404551304, 0.9878435052917216, 0.541054395507377, 0.45781525773701126, 0.9701877831430956, 0.7157645399643273, 0.9311618203017141, 0.06717336514614355, 0.9957397579788311, 0.460530803338409, 0.994406671132398, 0.0027394123171691404, 0.0027394123171691404, 0.9884722407652698, 0.7053596438276207, 0.1679427723399097, 0.06717710893596388, 0.9850063370296517, 0.9982132503848178, 0.6454504600498056, 0.2868668711332469, 0.37056564324883884, 0.6215939822238586, 0.9874211204274534, 0.010732838265515798, 0.45306506045706707, 0.5285759038665783, 0.577453121122498, 0.6538808770922948, 0.30607189991554223, 0.027824718174140204, 0.801603210264483, 0.15658138509539463, 0.03271849837814216, 0.004674071196877452, 0.954048201421415, 0.7845196575240109, 0.11207423678914441, 0.8605786612808709, 0.9799124744219682, 0.018703723578178646, 0.9921187621852868, 0.7188185713466311, 0.7944402579237065, 0.12297836809964498, 0.007378702085978698, 0.07132745349779408, 0.9250458799282091], \"Term\": [\"access\", \"accident\", \"accident\", \"acquire\", \"act\", \"actually\", \"address\", \"address\", \"address\", \"adjective\", \"affair\", \"agency\", \"ai\", \"also\", \"also\", \"also\", \"also\", \"analyze\", \"animal\", \"annoy\", \"annual\", \"apple\", \"applicable\", \"applicable\", \"application\", \"application\", \"appreciate\", \"approach\", \"approach\", \"approach\", \"apr\", \"argue\", \"argue\", \"argue\", \"argument\", \"argument\", \"arkansa\", \"arm\", \"arm\", \"article\", \"article\", \"article\", \"artificial\", \"assert\", \"associate\", \"associate\", \"atf\", \"atheist\", \"attend\", \"au\", \"auto\", \"available\", \"average\", \"average\", \"ax\", \"back\", \"back\", \"battery\", \"bbbllluueeee\", \"be\", \"believe\", \"believe\", \"bench\", \"bible\", \"big\", \"big\", \"bike\", \"biker\", \"bird\", \"bit\", \"bit\", \"bit\", \"bit\", \"blind\", \"block\", \"blood\", \"blood\", \"blue\", \"board\", \"board\", \"boss\", \"brian\", \"bruin\", \"btw\", \"bug\", \"bull\", \"burn\", \"burn\", \"bus\", \"cage\", \"cap\", \"car\", \"car\", \"card\", \"career\", \"carnegie_mellon\", \"carry\", \"carry\", \"carry\", \"carry\", \"cause\", \"cd\", \"cd\", \"cell\", \"chance\", \"channel\", \"chastity\", \"chemistry\", \"child\", \"child\", \"chip\", \"chip\", \"choose\", \"christian\", \"christianity\", \"christianity\", \"citizen\", \"city\", \"city\", \"civilian\", \"clark\", \"client\", \"closed\", \"closing\", \"code\", \"coffee\", \"come\", \"commit\", \"communication\", \"comp_graphic\", \"compact\", \"complaint\", \"computer\", \"computer_science\", \"computer_science\", \"config\", \"constitution\", \"construct\", \"consultant\", \"cont\", \"context\", \"contrary\", \"control\", \"control\", \"control\", \"control\", \"cop\", \"copper\", \"core\", \"correctly\", \"country\", \"country\", \"country\", \"course\", \"cpu\", \"cpu\", \"crazy\", \"creation\", \"crime\", \"criminal\", \"critical\", \"dance\", \"dangerous\", \"datum\", \"datum\", \"david_veal\", \"day\", \"day\", \"day\", \"death\", \"death\", \"death\", \"defense\", \"defense\", \"define\", \"define\", \"degree\", \"degree\", \"demand\", \"dependant\", \"depth\", \"derive\", \"design\", \"design\", \"destruction\", \"det\", \"device\", \"device\", \"die\", \"die\", \"die\", \"different\", \"display\", \"dissemination\", \"distribution\", \"distribution_usa\", \"division\", \"division\", \"division\", \"division\", \"do\", \"do\", \"dog\", \"doubtful\", \"dream\", \"drive\", \"driver\", \"driver\", \"drug\", \"early\", \"early\", \"early\", \"eat\", \"economic\", \"edge\", \"educate\", \"electric\", \"electronic\", \"element\", \"element\", \"elevator\", \"email\", \"encrypt\", \"encryption\", \"engage\", \"enough\", \"ensure\", \"equal\", \"error\", \"essential\", \"even\", \"even\", \"everywhere\", \"excuse\", \"exe\", \"exist\", \"exist\", \"exist\", \"exist\", \"export\", \"ext\", \"extract\", \"fair\", \"faith\", \"family\", \"family\", \"fan\", \"fanatical\", \"far\", \"fatal\", \"feasible\", \"federal\", \"fee\", \"file\", \"file\", \"fire\", \"firearm\", \"first\", \"first\", \"first\", \"first\", \"first\", \"flip\", \"follow\", \"follow\", \"follow\", \"follow\", \"food\", \"food\", \"fool\", \"fool\", \"forever\", \"frame\", \"franchise\", \"front\", \"front\", \"frontier\", \"fund\", \"game\", \"gary_dare\", \"gather\", \"gay\", \"geezer\", \"generally\", \"gentile\", \"get\", \"get\", \"get\", \"get\", \"get\", \"ggggooooooo\", \"gif\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"goal\", \"good\", \"good\", \"good\", \"good\", \"gord\", \"gordon_bank\", \"government\", \"govt\", \"grab\", \"grade\", \"grand\", \"grant\", \"graphic\", \"group\", \"group\", \"group\", \"growth\", \"guide\", \"guilty\", \"gun\", \"gun\", \"gun\", \"gunshot\", \"hammer\", \"handgun\", \"happen\", \"hard_drive\", \"hawk\", \"heal\", \"hear\", \"hit\", \"hit\", \"hitter\", \"holly\", \"holster\", \"homosexual\", \"host\", \"host\", \"hot\", \"human\", \"human\", \"human\", \"ide\", \"idle\", \"image\", \"implement\", \"imply\", \"import\", \"important\", \"important\", \"include\", \"include\", \"include\", \"include\", \"increase\", \"individual\", \"inferior\", \"inflict\", \"info\", \"information\", \"information\", \"informative\", \"injury\", \"injury\", \"instal\", \"intellect\", \"internet\", \"interpretation\", \"interpreter\", \"israeli\", \"issue\", \"issue\", \"issue\", \"jay\", \"je\", \"jxp_skepticism\", \"key\", \"key\", \"kid\", \"kit\", \"know\", \"know\", \"know\", \"knowledge\", \"koresh\", \"lady\", \"last_year\", \"launch\", \"law\", \"lawyer\", \"layer\", \"leaf\", \"leafs\", \"league\", \"least\", \"let\", \"let\", \"lethal\", \"liar\", \"license\", \"license\", \"life\", \"line\", \"line\", \"line\", \"list\", \"list\", \"list\", \"listen\", \"literature\", \"little\", \"live\", \"logic\", \"look\", \"look\", \"look\", \"lose\", \"lose\", \"luck\", \"lucky\", \"lunatic\", \"m\", \"mail\", \"maine\", \"mainstream\", \"major\", \"major\", \"major\", \"make\", \"make\", \"man\", \"man\", \"man\", \"manual\", \"manufacture\", \"manufacturer\", \"marriage\", \"marriage\", \"mask\", \"max\", \"medical\", \"meet\", \"member\", \"member\", \"memory\", \"mention\", \"message\", \"message\", \"mhz\", \"mhz\", \"microwave\", \"middle\", \"middle_east\", \"militia\", \"miss\", \"monitor\", \"monitor\", \"moral\", \"moral\", \"morality\", \"motherboard\", \"motif\", \"motorcycle\", \"mouse\", \"mouse\", \"mp\", \"much\", \"nail\", \"nearly\", \"need\", \"need\", \"need\", \"network\", \"network\", \"new\", \"new\", \"new\", \"next\", \"next\", \"niguma\", \"ninth\", \"nntp_poste\", \"nntp_poste\", \"north\", \"ns\", \"object\", \"obligation\", \"obp\", \"officer\", \"okay\", \"opinion\", \"orbit\", \"orbital\", \"organization\", \"organization\", \"organization\", \"organization\", \"originator\", \"os\", \"out\", \"owner\", \"paint\", \"paraphrase\", \"pentium\", \"people\", \"people\", \"people\", \"perfect\", \"performance\", \"permanent\", \"phase\", \"phds\", \"phds\", \"phone\", \"photo\", \"phrase\", \"physically\", \"pick\", \"pilot\", \"pin\", \"pistol\", \"pit\", \"pit\", \"play\", \"play\", \"play\", \"play\", \"player\", \"playoff\", \"plot\", \"pocket\", \"point\", \"police\", \"policy\", \"policy\", \"political\", \"popular\", \"possession\", \"pre\", \"prediction\", \"prediction\", \"present\", \"present\", \"president\", \"pretty\", \"pretty\", \"pretty\", \"prevent\", \"private\", \"private\", \"pro\", \"probability\", \"probably\", \"problem\", \"problem\", \"procedure\", \"processor\", \"product\", \"product\", \"professor\", \"program\", \"programmer\", \"proper\", \"property\", \"protect\", \"provide\", \"provide\", \"provide\", \"public\", \"public\", \"purdue_university\", \"purpose\", \"purpose\", \"query\", \"quit\", \"quite\", \"ram\", \"ranger\", \"ray_trace\", \"rbi\", \"really\", \"reduce\", \"reflect\", \"regulator\", \"relationship\", \"religion\", \"religion\", \"rely\", \"repeat\", \"replace\", \"replace\", \"research\", \"research\", \"respond\", \"revelation\", \"reverse\", \"review\", \"rifle\", \"right\", \"right\", \"right\", \"right\", \"rise\", \"rocket\", \"roof\", \"root\", \"rough\", \"roughly\", \"run\", \"run\", \"run\", \"run\", \"run\", \"runs_score\", \"s\", \"s\", \"safe\", \"safety\", \"sake\", \"sake\", \"sale\", \"say\", \"say\", \"say\", \"say\", \"scene\", \"score\", \"scoring\", \"screw\", \"scripture\", \"scsi\", \"seal\", \"season\", \"second_amendment\", \"section\", \"section\", \"secure\", \"see\", \"see\", \"see\", \"see\", \"seed\", \"seem\", \"seizure\", \"semi\", \"send\", \"send\", \"sentence\", \"separate\", \"server\", \"service\", \"sex\", \"shade\", \"shameful\", \"shoot\", \"shoot\", \"shop\", \"shotgun\", \"shuttle\", \"sin\", \"sit\", \"slg\", \"society\", \"software\", \"souviens\", \"space\", \"space\", \"space_station\", \"speed\", \"speed\", \"speedstar\", \"spending\", \"spread\", \"spread\", \"st\", \"start\", \"start\", \"state\", \"state\", \"statement\", \"statement\", \"statistic\", \"statistic\", \"stay\", \"steve_hendrick\", \"stone\", \"stream\", \"street\", \"street\", \"stretch\", \"study\", \"substantial\", \"supply\", \"sure\", \"sure\", \"surrender\", \"survive\", \"survivor\", \"suspicious\", \"switch\", \"system\", \"system\", \"system\", \"tail\", \"take\", \"take\", \"take\", \"talk\", \"tank\", \"tax\", \"teach\", \"teach\", \"team\", \"technology\", \"tell\", \"temperature\", \"tenn\", \"therefore\", \"therefore\", \"thigh\", \"thing\", \"think\", \"think\", \"thor\", \"tiff\", \"time\", \"time\", \"time\", \"title\", \"today\", \"today\", \"tor\", \"tough\", \"tournament\", \"trade\", \"tree\", \"troop\", \"truck\", \"true\", \"truly\", \"truth\", \"try\", \"try\", \"turbo\", \"turk\", \"turkish\", \"umaine\", \"unarmed\", \"unfortunately\", \"uniform\", \"unit\", \"unite\", \"univ\", \"use\", \"use\", \"use\", \"use\", \"user\", \"uunet\", \"valid\", \"vga\", \"video\", \"village\", \"village\", \"vote\", \"walsh\", \"want\", \"want\", \"water\", \"waterloo\", \"way\", \"way\", \"way\", \"weapon\", \"wear\", \"wear\", \"wear\", \"weeks_ago\", \"well\", \"western\", \"western\", \"win\", \"win\", \"window\", \"window\", \"wing\", \"wing\", \"winnipeg_jet\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"worship\", \"wound\", \"wound\", \"wrist\", \"write\", \"write\", \"wrong\", \"xavi\", \"year\", \"year\", \"year\", \"year\", \"yeast\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 20, 13, 12, 14, 19, 11, 6, 5, 2, 7, 8, 9, 15, 3, 10, 17, 1, 18, 16]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el867112095051360608770336\", ldavis_el867112095051360608770336_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el867112095051360608770336\", ldavis_el867112095051360608770336_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el867112095051360608770336\", ldavis_el867112095051360608770336_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.392963 -0.062834       1        1  46.697607\n",
       "19     0.325152  0.156084       2        1  16.884973\n",
       "12     0.239788 -0.276574       3        1   9.873119\n",
       "11     0.008903 -0.048605       4        1   7.211826\n",
       "13     0.145806  0.249892       5        1   5.976938\n",
       "18     0.151397  0.022354       6        1   5.956382\n",
       "10    -0.029065 -0.029282       7        1   1.864826\n",
       "5     -0.044673 -0.020059       8        1   1.395458\n",
       "4     -0.091331 -0.008883       9        1   1.117043\n",
       "1     -0.092170  0.013215      10        1   0.928895\n",
       "6     -0.097733  0.000466      11        1   0.661599\n",
       "7     -0.102849 -0.000131      12        1   0.382749\n",
       "8     -0.105412  0.000520      13        1   0.280098\n",
       "14    -0.103105  0.000239      14        1   0.188920\n",
       "2     -0.103197  0.000342      15        1   0.182493\n",
       "9     -0.101484  0.000326      16        1   0.136626\n",
       "16    -0.099333  0.001225      17        1   0.102166\n",
       "0     -0.098038  0.000690      18        1   0.065775\n",
       "17    -0.099026  0.000480      19        1   0.061317\n",
       "15    -0.096594  0.000536      20        1   0.031191, topic_info=              Term         Freq        Total Category  logprob  loglift\n",
       "6516            ax  5588.000000  5588.000000  Default   30.000  30.0000\n",
       "72            year   406.000000   406.000000  Default   29.000  29.0000\n",
       "111         system   461.000000   461.000000  Default   28.000  28.0000\n",
       "173            run   286.000000   286.000000  Default   27.000  27.0000\n",
       "129          drive   252.000000   252.000000  Default   26.000  26.0000\n",
       "...            ...          ...          ...      ...      ...      ...\n",
       "4936           ice     0.002644     0.769794  Topic20   -9.619   2.3988\n",
       "5995        wisdom     0.002643     0.769768  Topic20   -9.619   2.3988\n",
       "4826  transmission     0.002644     0.769787  Topic20   -9.619   2.3988\n",
       "6859        hockey     0.002644     0.769809  Topic20   -9.619   2.3988\n",
       "1613       monitor     0.002644    62.914734  Topic20   -9.619  -2.0046\n",
       "\n",
       "[838 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "1090      2  0.996521    access\n",
       "2817      1  0.952667  accident\n",
       "2817     12  0.036641  accident\n",
       "192       5  0.992316   acquire\n",
       "2459      3  0.988006       act\n",
       "...     ...       ...       ...\n",
       "72        1  0.794440      year\n",
       "72        3  0.122978      year\n",
       "72        6  0.007379      year\n",
       "72        8  0.071327      year\n",
       "2233     10  0.925046     yeast\n",
       "\n",
       "[807 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 20, 13, 12, 14, 19, 11, 6, 5, 2, 7, 8, 9, 15, 3, 10, 17, 1, 18, 16])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "      <td>16</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
       "      <td>5</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>From: leunggm@odin.control.utoronto.ca (Gary L...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>From: rpwhite@cs.nps.navy.mil (rpwhite)\\nSubje...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From: csyphers@uafhp..uark.edu (Chris Syphers)...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From: nagle@netcom.com (John Nagle)\\nSubject: ...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From: r4938585@joplin.biosci.arizona.edu (Doug...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>From: jonh@david.wheaton.edu (Jonathan Hayward...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From: jimf@centerline.com (Jim Frost)\\nSubject...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>From: mrh@iastate.edu (Michael R Hartman)\\nSub...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Subject: Teenage acne\\nFrom: pchurch@swell.act...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>From: xandor@unixg.ubc.ca (John Gilbert )\\nSub...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>From: ayr1@cunixa.cc.columbia.edu (Amir Y Rose...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>From: joec@hilbert.cyprs.rain.com ( Joe Cipale...</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>From: dchhabra@stpl.ists.ca (Deepak Chhabra)\\n...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>From: static@iat.holonet.net (Joe Ehrlich)\\nSu...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>From: ebrandt@jarthur.claremont.edu (Eli Brand...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>From: behanna@syl.nj.nec.com (Chris BeHanna)\\n...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>From: bressler@iftccu.ca.boeing.com (Rick Bres...</td>\n",
       "      <td>16</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>From:  (Sean Garrison)\\nSubject: Re: Bonilla\\n...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>From: root@ncube.com (Operator)\\nSubject: Re: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>From: ab245@cleveland.Freenet.Edu (Sam Latonia...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>From: cmeyer@bloch.Stanford.EDU (Craig Meyer)\\...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>From: Robert Everett Brunskill &lt;rb6t+@andrew.c...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>From: vng@iscs.nus.sg\\nSubject: Wyse 60 Termin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>From: speedy@engr.latech.edu (Speedy Mercer)\\n...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>From: tg@cs.toronto.edu (Tom Glinos)\\nSubject:...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>From: 18084TM@msu.edu (Tom)\\nSubject: Golden &amp;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  target  \\\n",
       "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...      16   \n",
       "6   From: bmdelane@quads.uchicago.edu (brian manni...      13   \n",
       "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...       3   \n",
       "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...       2   \n",
       "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...       4   \n",
       "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "11  From: david@terminus.ericsson.se (David Bold)\\...      19   \n",
       "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...       4   \n",
       "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...      14   \n",
       "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...       6   \n",
       "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...       0   \n",
       "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1   \n",
       "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...       7   \n",
       "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...      12   \n",
       "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...       5   \n",
       "20  From: keith@cco.caltech.edu (Keith Allan Schne...       0   \n",
       "21  From: leunggm@odin.control.utoronto.ca (Gary L...      10   \n",
       "22  From: rpwhite@cs.nps.navy.mil (rpwhite)\\nSubje...       6   \n",
       "23  From: csyphers@uafhp..uark.edu (Chris Syphers)...       2   \n",
       "24  From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...       4   \n",
       "25  From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...       1   \n",
       "26  From: nagle@netcom.com (John Nagle)\\nSubject: ...      12   \n",
       "27  From: r4938585@joplin.biosci.arizona.edu (Doug...       9   \n",
       "28  From: jonh@david.wheaton.edu (Jonathan Hayward...      15   \n",
       "29  From: jimf@centerline.com (Jim Frost)\\nSubject...       7   \n",
       "30  From: mrh@iastate.edu (Michael R Hartman)\\nSub...       6   \n",
       "31  Subject: Teenage acne\\nFrom: pchurch@swell.act...      13   \n",
       "32  From: xandor@unixg.ubc.ca (John Gilbert )\\nSub...      12   \n",
       "33  From: ayr1@cunixa.cc.columbia.edu (Amir Y Rose...      17   \n",
       "34  From: joec@hilbert.cyprs.rain.com ( Joe Cipale...      18   \n",
       "35  From: dchhabra@stpl.ists.ca (Deepak Chhabra)\\n...      10   \n",
       "36  From: static@iat.holonet.net (Joe Ehrlich)\\nSu...       8   \n",
       "37  From: ebrandt@jarthur.claremont.edu (Eli Brand...      11   \n",
       "38  From: behanna@syl.nj.nec.com (Chris BeHanna)\\n...       8   \n",
       "39  From: bressler@iftccu.ca.boeing.com (Rick Bres...      16   \n",
       "40  From:  (Sean Garrison)\\nSubject: Re: Bonilla\\n...       9   \n",
       "41  From: root@ncube.com (Operator)\\nSubject: Re: ...       4   \n",
       "42  From: ab245@cleveland.Freenet.Edu (Sam Latonia...       3   \n",
       "43  From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...       9   \n",
       "44  From: cmeyer@bloch.Stanford.EDU (Craig Meyer)\\...       9   \n",
       "45  From: Robert Everett Brunskill <rb6t+@andrew.c...       4   \n",
       "46  From: vng@iscs.nus.sg\\nSubject: Wyse 60 Termin...       4   \n",
       "47  From: speedy@engr.latech.edu (Speedy Mercer)\\n...       8   \n",
       "48  From: tg@cs.toronto.edu (Tom Glinos)\\nSubject:...      12   \n",
       "49  From: 18084TM@msu.edu (Tom)\\nSubject: Golden &...      14   \n",
       "\n",
       "                target_names  \n",
       "0                  rec.autos  \n",
       "1      comp.sys.mac.hardware  \n",
       "2      comp.sys.mac.hardware  \n",
       "3              comp.graphics  \n",
       "4                  sci.space  \n",
       "5         talk.politics.guns  \n",
       "6                    sci.med  \n",
       "7   comp.sys.ibm.pc.hardware  \n",
       "8    comp.os.ms-windows.misc  \n",
       "9      comp.sys.mac.hardware  \n",
       "10           rec.motorcycles  \n",
       "11        talk.religion.misc  \n",
       "12     comp.sys.mac.hardware  \n",
       "13                 sci.space  \n",
       "14              misc.forsale  \n",
       "15               alt.atheism  \n",
       "16             comp.graphics  \n",
       "17                 rec.autos  \n",
       "18           sci.electronics  \n",
       "19            comp.windows.x  \n",
       "20               alt.atheism  \n",
       "21          rec.sport.hockey  \n",
       "22              misc.forsale  \n",
       "23   comp.os.ms-windows.misc  \n",
       "24     comp.sys.mac.hardware  \n",
       "25             comp.graphics  \n",
       "26           sci.electronics  \n",
       "27        rec.sport.baseball  \n",
       "28    soc.religion.christian  \n",
       "29                 rec.autos  \n",
       "30              misc.forsale  \n",
       "31                   sci.med  \n",
       "32           sci.electronics  \n",
       "33     talk.politics.mideast  \n",
       "34        talk.politics.misc  \n",
       "35          rec.sport.hockey  \n",
       "36           rec.motorcycles  \n",
       "37                 sci.crypt  \n",
       "38           rec.motorcycles  \n",
       "39        talk.politics.guns  \n",
       "40        rec.sport.baseball  \n",
       "41     comp.sys.mac.hardware  \n",
       "42  comp.sys.ibm.pc.hardware  \n",
       "43        rec.sport.baseball  \n",
       "44        rec.sport.baseball  \n",
       "45     comp.sys.mac.hardware  \n",
       "46     comp.sys.mac.hardware  \n",
       "47           rec.motorcycles  \n",
       "48           sci.electronics  \n",
       "49                 sci.space  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how to infer pyLDAvis’s output?\n",
    "\n",
    "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "\n",
    "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
    "\n",
    "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n",
    "\n",
    "We have successfully built a good looking topic model.\n",
    "\n",
    "Given our prior knowledge of the number of natural topics in the document, finding the best model was fairly straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling with BERT  \n",
    "\n",
    "Three main algorithm components\n",
    "1. Embed Documents: Extract document embeddings with Sentence Transformers. Since the data we are working with are article titles, we will need to obtain sentence embeddings, which BERTopic lets us do conveniently, by employing its default sentence transformer model paraphrase-MiniLM-L6-v2.\n",
    "2. Cluster Documents: Create groups of similar documents with UMAP (to reduce the dimensionality of embeddings) and HDBSCAN (to identify and cluster semantically similar documents)\n",
    "3. Create Topic Representation: Extract and reduce topics with c-TF-IDF (class-based term frequency, inverse document frequency). If you are unfamiliar with TF-IDF in the first place, all you need to know in order to generally grasp what is going on here is one thing: it allows for comparing the importance of words between documents by computing the frequency of a word in a given document and also the measure of how prevalent the word is in the entire corpus. Now, if we instead treat all documents in a single cluster as a single document and then perform TF-IDF, the result would be importance scores for words within a cluster. The more important words are within a cluster, the more representative they are of that topic. Therefore, we can obtain keyword-based descriptions for each topic! This is super powerful when it comes to inferring meaning from the groupings yielded by any unsupervised clustering technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bertopic\n",
    "# !pip install bertopic[visualization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(min_topic_size=70, n_gram_range=(1,3), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, _ = topic_model.fit_transform(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0_the_to_of_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1_the_to_and_in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count             Name\n",
       "0      0    892  0_the_to_of_and\n",
       "1      1    108  1_the_to_and_in"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.061614601895700435),\n",
       " ('to', 0.02906812325047156),\n",
       " ('and', 0.027099973271320396),\n",
       " ('in', 0.025387093183087617),\n",
       " ('of', 0.02523615989598884),\n",
       " ('he', 0.01891689283123492),\n",
       " ('that', 0.018160163280074318),\n",
       " ('for', 0.015790882488020297),\n",
       " ('is', 0.015627992999941914),\n",
       " ('was', 0.013540629117362939)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_nr = freq.iloc[1][\"Topic\"] # select a frequent topic\n",
    "topic_model.get_topic(topic_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
